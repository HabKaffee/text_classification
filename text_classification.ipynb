{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pymorphy2\n",
    "# %pip install nltk\n",
    "# %pip install sklearn\n",
    "# %pip install wordcloud\n",
    "# %pip install stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/habkaffee/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "from scipy.sparse import *\n",
    "import stop_words\n",
    "import tqdm\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import pickle\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.metrics import precision_score, accuracy_score, recall_score, f1_score\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_conf_matrix(y_true, y_pred, Y):\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    cm_display = ConfusionMatrixDisplay(conf_matrix, display_labels=Y.unique())\n",
    "    cm_display.plot()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_grid_search_info(model):\n",
    "    print(f'Best estimator -> {model.best_estimator_}\\n\\\n",
    "Best Score -> {model.best_score_}\\n\\\n",
    "Best Parameters -> {model.best_params_}\\n\\\n",
    "Best index -> {model.best_index_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gridsearch_for_model(model, parameters : dict) -> GridSearchCV:\n",
    "    model_grid = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=parameters,\n",
    "        scoring=['f1_micro', 'accuracy', 'recall_macro'],\n",
    "        refit='f1_micro',\n",
    "        cv=3,\n",
    "        verbose=3,\n",
    "        error_score=0\n",
    "    )\n",
    "    return model_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(path:str, model):\n",
    "    with open(path, mode='wb') as pickle_file:\n",
    "        pickle.dump(model, pickle_file)\n",
    "\n",
    "def load_model(path:str):\n",
    "    with open('./models/lin_svc.pkl', mode='rb') as pickle_file:\n",
    "        model = pickle.load(pickle_file)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(y_test, y_pred):\n",
    "    print(f'f1_micro = {f1_score(y_test, y_pred, average=\"micro\")}\\nrecall_score = {recall_score(y_test, y_pred, average=\"macro\")}\\nprecision_score = {precision_score(y_test, y_pred, average=\"macro\")}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class Index</th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Wall St. Bears Claw Back Into the Black (Reuters)</td>\n",
       "      <td>Reuters - Short-sellers, Wall Street's dwindli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
       "      <td>Reuters - Private investment firm Carlyle Grou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters)</td>\n",
       "      <td>Reuters - Soaring crude prices plus worries\\ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
       "      <td>Reuters - Authorities have halted oil export\\f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Oil prices soar to all-time record, posing new...</td>\n",
       "      <td>AFP - Tearaway world oil prices, toppling reco...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class Index                                              Title  \\\n",
       "0            3  Wall St. Bears Claw Back Into the Black (Reuters)   \n",
       "1            3  Carlyle Looks Toward Commercial Aerospace (Reu...   \n",
       "2            3    Oil and Economy Cloud Stocks' Outlook (Reuters)   \n",
       "3            3  Iraq Halts Oil Exports from Main Southern Pipe...   \n",
       "4            3  Oil prices soar to all-time record, posing new...   \n",
       "\n",
       "                                         Description  \n",
       "0  Reuters - Short-sellers, Wall Street's dwindli...  \n",
       "1  Reuters - Private investment firm Carlyle Grou...  \n",
       "2  Reuters - Soaring crude prices plus worries\\ab...  \n",
       "3  Reuters - Authorities have halted oil export\\f...  \n",
       "4  AFP - Tearaway world oil prices, toppling reco...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = pd.read_csv(\"data/test.csv\")\n",
    "train_dataset = pd.read_csv(\"data/train.csv\")\n",
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's prepare copies of train dataset with 3 different text cleaning techniques (one method at a time):  \n",
    "- stop words removing\n",
    "- trash removing\n",
    "- digits removing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reuters - Short-sellers, Wall Street's dwindli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reuters - Private investment firm Carlyle Grou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Reuters - Soaring crude prices plus worries\\ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Reuters - Authorities have halted oil export\\f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFP - Tearaway world oil prices, toppling reco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119995</th>\n",
       "      <td>KARACHI (Reuters) - Pakistani President Perve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119996</th>\n",
       "      <td>Red Sox general manager Theo Epstein acknowled...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119997</th>\n",
       "      <td>The Miami Dolphins will put their courtship of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119998</th>\n",
       "      <td>PITTSBURGH at NY GIANTS Time: 1:30 p.m. Line: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119999</th>\n",
       "      <td>INDIANAPOLIS -- All-Star Vince Carter was trad...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        0\n",
       "0       Reuters - Short-sellers, Wall Street's dwindli...\n",
       "1       Reuters - Private investment firm Carlyle Grou...\n",
       "2       Reuters - Soaring crude prices plus worries\\ab...\n",
       "3       Reuters - Authorities have halted oil export\\f...\n",
       "4       AFP - Tearaway world oil prices, toppling reco...\n",
       "...                                                   ...\n",
       "119995   KARACHI (Reuters) - Pakistani President Perve...\n",
       "119996  Red Sox general manager Theo Epstein acknowled...\n",
       "119997  The Miami Dolphins will put their courtship of...\n",
       "119998  PITTSBURGH at NY GIANTS Time: 1:30 p.m. Line: ...\n",
       "119999  INDIANAPOLIS -- All-Star Vince Carter was trad...\n",
       "\n",
       "[120000 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_splitted_texts = [line.split('\\n') for line in train_dataset['Description']]\n",
    "pd.DataFrame(train_dataset_splitted_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reuters - Short-sellers, Wall Street's dwindli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reuters - Private investment firm Carlyle Grou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Reuters - Soaring crude prices plus worries\\ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Reuters - Authorities have halted oil export\\f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFP - Tearaway world oil prices, toppling reco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119995</th>\n",
       "      <td>KARACHI (Reuters) - Pakistani President Perve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119996</th>\n",
       "      <td>Red Sox general manager Theo Epstein acknowled...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119997</th>\n",
       "      <td>The Miami Dolphins will put their courtship of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119998</th>\n",
       "      <td>PITTSBURGH at NY GIANTS Time: 1:30 p.m. Line: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119999</th>\n",
       "      <td>INDIANAPOLIS -- All-Star Vince Carter was trad...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        0\n",
       "0       Reuters - Short-sellers, Wall Street's dwindli...\n",
       "1       Reuters - Private investment firm Carlyle Grou...\n",
       "2       Reuters - Soaring crude prices plus worries\\ab...\n",
       "3       Reuters - Authorities have halted oil export\\f...\n",
       "4       AFP - Tearaway world oil prices, toppling reco...\n",
       "...                                                   ...\n",
       "119995   KARACHI (Reuters) - Pakistani President Perve...\n",
       "119996  Red Sox general manager Theo Epstein acknowled...\n",
       "119997  The Miami Dolphins will put their courtship of...\n",
       "119998  PITTSBURGH at NY GIANTS Time: 1:30 p.m. Line: ...\n",
       "119999  INDIANAPOLIS -- All-Star Vince Carter was trad...\n",
       "\n",
       "[120000 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_removed_stopwords = [' '.join([word if word not in stop_words.get_stop_words('en') else '' for word in text]) for text in train_dataset_splitted_texts]\n",
    "pd.DataFrame(train_removed_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reuters  Shortsellers Wall Streets dwindlingba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reuters  Private investment firm Carlyle Group...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Reuters  Soaring crude prices plus worriesabou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Reuters  Authorities have halted oil exportflo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFP  Tearaway world oil prices toppling record...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119995</th>\n",
       "      <td>KARACHI Reuters  Pakistani President Pervez M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119996</th>\n",
       "      <td>Red Sox general manager Theo Epstein acknowled...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119997</th>\n",
       "      <td>The Miami Dolphins will put their courtship of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119998</th>\n",
       "      <td>PITTSBURGH at NY GIANTS Time 130 pm Line Steel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119999</th>\n",
       "      <td>INDIANAPOLIS  AllStar Vince Carter was traded ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        0\n",
       "0       Reuters  Shortsellers Wall Streets dwindlingba...\n",
       "1       Reuters  Private investment firm Carlyle Group...\n",
       "2       Reuters  Soaring crude prices plus worriesabou...\n",
       "3       Reuters  Authorities have halted oil exportflo...\n",
       "4       AFP  Tearaway world oil prices toppling record...\n",
       "...                                                   ...\n",
       "119995   KARACHI Reuters  Pakistani President Pervez M...\n",
       "119996  Red Sox general manager Theo Epstein acknowled...\n",
       "119997  The Miami Dolphins will put their courtship of...\n",
       "119998  PITTSBURGH at NY GIANTS Time 130 pm Line Steel...\n",
       "119999  INDIANAPOLIS  AllStar Vince Carter was traded ...\n",
       "\n",
       "[120000 rows x 1 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_removed_punctuation = [' '.join([(' '.join(text)).translate(str.maketrans('', '', str(\"!\\\"\\'(),-./:;?\\\\`\")))]) for text in train_dataset_splitted_texts]\n",
    "pd.DataFrame(train_removed_punctuation)\n",
    "# train_removed_punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_symbols = u''.join(['№', '«', 'ђ', '°', '±', '‚', 'ћ', '‰', '…', '»', 'ѓ', 'µ', '·', 'ґ', 'њ', 'ї', 'џ', 'є', '‹',\n",
    "                            '‡', '†', '¶', 'ќ', '€', '“', 'ў', '§', '„', '”', '\\ufeff', '’', 'љ', '›', '•', '—', '‘', \n",
    "                            '\\x7f', '\\xad', '¤', '\\xa0', '\\u200b', '–']) + string.punctuation\n",
    "regex_symb = re.compile('[%s]' % re.escape(exclude_symbols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reuters Shortsellers Wall Streets dwindlingban...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reuters Private investment firm Carlyle Groupw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Reuters Soaring crude prices plus worriesabout...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Reuters Authorities have halted oil exportflow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFP Tearaway world oil prices toppling records...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119995</th>\n",
       "      <td>KARACHI Reuters Pakistani President Pervez Mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119996</th>\n",
       "      <td>Red Sox general manager Theo Epstein acknowled...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119997</th>\n",
       "      <td>The Miami Dolphins will put their courtship of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119998</th>\n",
       "      <td>PITTSBURGH at NY GIANTS Time 130 pm Line Steel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119999</th>\n",
       "      <td>INDIANAPOLIS AllStar Vince Carter was traded b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        0\n",
       "0       Reuters Shortsellers Wall Streets dwindlingban...\n",
       "1       Reuters Private investment firm Carlyle Groupw...\n",
       "2       Reuters Soaring crude prices plus worriesabout...\n",
       "3       Reuters Authorities have halted oil exportflow...\n",
       "4       AFP Tearaway world oil prices toppling records...\n",
       "...                                                   ...\n",
       "119995   KARACHI Reuters Pakistani President Pervez Mu...\n",
       "119996  Red Sox general manager Theo Epstein acknowled...\n",
       "119997  The Miami Dolphins will put their courtship of...\n",
       "119998  PITTSBURGH at NY GIANTS Time 130 pm Line Steel...\n",
       "119999  INDIANAPOLIS AllStar Vince Carter was traded b...\n",
       "\n",
       "[120000 rows x 1 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_removed_trash = [regex_symb.sub('', ' '.join(text)) for text in train_dataset_splitted_texts]\n",
    "train_removed_trash = [re.sub(r' +', ' ', text) for text in train_removed_trash]\n",
    "pd.DataFrame(train_removed_trash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reuters - Short-sellers, Wall Street's dwindli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reuters - Private investment firm Carlyle Grou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Reuters - Soaring crude prices plus worries\\ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Reuters - Authorities have halted oil export\\f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFP - Tearaway world oil prices, toppling reco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119995</th>\n",
       "      <td>KARACHI (Reuters) - Pakistani President Perve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119996</th>\n",
       "      <td>Red Sox general manager Theo Epstein acknowled...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119997</th>\n",
       "      <td>The Miami Dolphins will put their courtship of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119998</th>\n",
       "      <td>PITTSBURGH at NY GIANTS Time: : p.m. Line: Ste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119999</th>\n",
       "      <td>INDIANAPOLIS -- All-Star Vince Carter was trad...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        0\n",
       "0       Reuters - Short-sellers, Wall Street's dwindli...\n",
       "1       Reuters - Private investment firm Carlyle Grou...\n",
       "2       Reuters - Soaring crude prices plus worries\\ab...\n",
       "3       Reuters - Authorities have halted oil export\\f...\n",
       "4       AFP - Tearaway world oil prices, toppling reco...\n",
       "...                                                   ...\n",
       "119995   KARACHI (Reuters) - Pakistani President Perve...\n",
       "119996  Red Sox general manager Theo Epstein acknowled...\n",
       "119997  The Miami Dolphins will put their courtship of...\n",
       "119998  PITTSBURGH at NY GIANTS Time: : p.m. Line: Ste...\n",
       "119999  INDIANAPOLIS -- All-Star Vince Carter was trad...\n",
       "\n",
       "[120000 rows x 1 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex_digit = re.compile('[%s]' % re.escape(string.digits))\n",
    "train_removed_digits = [regex_digit.sub('', ' '.join(text)) for text in train_dataset_splitted_texts]\n",
    "pd.DataFrame(train_removed_digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words=stop_words.get_stop_words('en'), max_features=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = train_dataset[\"Class Index\"]\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/.local/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aren', 'can', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'let', 'll', 'mustn', 're', 'shan', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "CVect_stopwords = vectorizer.fit_transform(train_removed_stopwords).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(CVect_stopwords, Y, test_size=0.25, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters_logreg = {\n",
    "#     'penalty': ['l1', 'l2'],\n",
    "#     'C': [0.01, 0.1, 0.5, 1.0, 10.0],\n",
    "#     'solver': ['lbfgs', 'liblinear'],\n",
    "#     'max_iter': [100, 500]\n",
    "# }\n",
    "\n",
    "# grid_log = get_gridsearch_for_model(LogisticRegression(), parameters_logreg)\n",
    "\n",
    "# grid_log.fit(X_train, Y_train)\n",
    "# print_grid_search_info(grid_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score = 0.9016666666666667\n",
      "recall_score = 0.9014730717851448\n",
      "precision_score = 0.9013132593705164\n"
     ]
    }
   ],
   "source": [
    "# Y_pred_logreg = grid_log.predict(X_test)\n",
    "# print_metrics(Y_test, Y_pred_logreg)\n",
    "# save_model('./models/log_reg.pkl', grid_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_linSVC = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'loss': ['hinge', 'squared_hinge'],\n",
    "    'C': np.linspace(0.001, 0.1, 5),\n",
    "    'max_iter': [1000, 3000, 5000],\n",
    "    'dual':[True]\n",
    "}\n",
    "\n",
    "grid_linearSVC = get_gridsearch_for_model(LinearSVC(), parameters_linSVC)\n",
    "\n",
    "grid_linearSVC.fit(X_train, Y_train)\n",
    "print_grid_search_info(grid_linearSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score = 0.9051999999999999\n",
      "recall_score = 0.9050006500418074\n",
      "precision_score = 0.9049231276210165\n"
     ]
    }
   ],
   "source": [
    "Y_pred_linSVC = grid_linearSVC.predict(X_test)\n",
    "print_metrics(Y_test, Y_pred_linSVC)\n",
    "save_model('./models/lin_svc.pkl', grid_linearSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MARK: Model is saved in KNN.pkl. Code commented to avoid exsistential crysis due to 5 hours of wasted time :D\n",
    "\n",
    "# parameters_KNN = {\n",
    "#     'n_neighbors' : [5, 6, 7],\n",
    "#     'weights' : ['uniform', 'distance'],\n",
    "#     'leaf_size' : [1, 2, 3],\n",
    "#     'n_jobs' : [10]\n",
    "# }\n",
    "\n",
    "# grid_KNN = get_gridsearch_for_model(KNeighborsClassifier(), parameters_KNN)\n",
    "\n",
    "# grid_KNN.fit(X_train, Y_train)\n",
    "# print_grid_search_info(grid_KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score = 0.5876333333333333\n",
      "recall_score = 0.5868685205825099\n",
      "precision_score = 0.6719880795980494\n"
     ]
    }
   ],
   "source": [
    "# Y_pred_KNN = grid_KNN.predict(X_test)\n",
    "# print_metrics(Y_test, Y_pred_KNN)\n",
    "# save_model('./models/KNN.pkl', grid_RFC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CVect_trash = vectorizer.fit_transform(train_removed_trash).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(CVect_trash, Y, test_size=0.25, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters_logreg = {\n",
    "#     'penalty': ['l1', 'l2'],\n",
    "#     'C': [0.01, 0.1, 0.5, 1.0, 10.0],\n",
    "#     'solver': ['lbfgs', 'liblinear'],\n",
    "#     'max_iter': [100, 500]\n",
    "# }\n",
    "\n",
    "# grid_log = get_gridsearch_for_model(LogisticRegression(), parameters_logreg)\n",
    "\n",
    "# grid_log.fit(X_train, Y_train)\n",
    "# print_grid_search_info(grid_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score = 0.8989\n",
      "recall_score = 0.8987174214816545\n",
      "precision_score = 0.8985895429774059\n"
     ]
    }
   ],
   "source": [
    "# Y_pred_logreg = grid_log.predict(X_test)\n",
    "# print_metrics(Y_test, Y_pred_logreg)\n",
    "# save_model('./models/log_reg_trash.pkl', grid_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_linSVC = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'loss': ['hinge', 'squared_hinge'],\n",
    "    'C': np.linspace(0.001, 0.1, 5),\n",
    "    'max_iter': [1000, 3000, 5000],\n",
    "    'dual':[True]\n",
    "}\n",
    "\n",
    "grid_linearSVC = get_gridsearch_for_model(LinearSVC(), parameters_linSVC)\n",
    "\n",
    "grid_linearSVC.fit(X_train, Y_train)\n",
    "print_grid_search_info(grid_linearSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_linSVC = grid_linearSVC.predict(X_test)\n",
    "print_metrics(Y_test, Y_pred_linSVC)\n",
    "save_model('./models/lin_svc_trash.pkl', grid_linearSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/.local/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aren', 'can', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'let', 'll', 'mustn', 're', 'shan', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "CVect_digits = vectorizer.fit_transform(train_removed_digits).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(CVect_digits, Y, test_size=0.25, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters_logreg = {\n",
    "#     'penalty': ['l1', 'l2'],\n",
    "#     'C': [0.01, 0.1, 0.5, 1.0, 10.0],\n",
    "#     'solver': ['lbfgs', 'liblinear'],\n",
    "#     'max_iter': [100, 500]\n",
    "# }\n",
    "\n",
    "# grid_log = get_gridsearch_for_model(LogisticRegression(), parameters_logreg)\n",
    "\n",
    "# grid_log.fit(X_train, Y_train)\n",
    "# print_grid_search_info(grid_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_micro = 0.9018333333333334\n",
      "recall_score = 0.9016440165316573\n",
      "precision_score = 0.9014961075002719\n"
     ]
    }
   ],
   "source": [
    "# Y_pred_logreg = grid_log.predict(X_test)\n",
    "# print_metrics(Y_test, Y_pred_logreg)\n",
    "# save_model('./models/log_reg_digits.pkl', grid_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_linSVC = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'loss': ['hinge', 'squared_hinge'],\n",
    "    'C': np.linspace(0.001, 0.1, 5),\n",
    "    'max_iter': [1000, 3000, 5000],\n",
    "    'dual':[True]\n",
    "}\n",
    "\n",
    "grid_linearSVC = get_gridsearch_for_model(LinearSVC(), parameters_linSVC)\n",
    "\n",
    "grid_linearSVC.fit(X_train, Y_train)\n",
    "print_grid_search_info(grid_linearSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_micro = 0.9048\n",
      "recall_score = 0.9046027739688296\n",
      "precision_score = 0.9045058874334311\n"
     ]
    }
   ],
   "source": [
    "Y_pred_linSVC = grid_linearSVC.predict(X_test)\n",
    "print_metrics(Y_test, Y_pred_linSVC)\n",
    "save_model('./models/lin_svc_digits.pkl', grid_linearSVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=stop_words.get_stop_words(\"en\"), max_features=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = train_dataset[\"Class Index\"]\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/.local/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aren', 'can', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'let', 'll', 'mustn', 're', 'shan', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "TF_IDF_stopwords = vectorizer.fit_transform(train_removed_stopwords).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(TF_IDF_stopwords, Y, test_size=0.25, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MARK: Train took 2 hours. Tooooooo long. LinearSVC takes about 10 mins for same/better results. ¬_¬\n",
    "\n",
    "# parameters_logreg = {\n",
    "#     'penalty': ['l1', 'l2'],\n",
    "#     'C': [0.01, 0.1, 0.5, 1.0, 10.0],\n",
    "#     'solver': ['lbfgs', 'liblinear'],\n",
    "#     'max_iter': [100, 500]\n",
    "# }\n",
    "\n",
    "# grid_log = get_gridsearch_for_model(LogisticRegression(), parameters_logreg)\n",
    "\n",
    "# grid_log.fit(X_train, Y_train)\n",
    "# print_grid_search_info(grid_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_micro = 0.9031333333333333\n",
      "recall_score = 0.9029454615604425\n",
      "precision_score = 0.9027714533817023\n"
     ]
    }
   ],
   "source": [
    "# Y_pred_logreg = grid_log.predict(X_test)\n",
    "# print_metrics(Y_test, Y_pred_logreg)\n",
    "# save_model('./models/tfidf_log_reg.pkl', grid_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_linSVC = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'loss': ['hinge', 'squared_hinge'],\n",
    "    'C': np.linspace(0.001, 0.1, 5),\n",
    "    'max_iter': [1000, 3000, 5000],\n",
    "    'dual':[True]\n",
    "}\n",
    "\n",
    "grid_linearSVC = get_gridsearch_for_model(LinearSVC(), parameters_linSVC)\n",
    "\n",
    "grid_linearSVC.fit(X_train, Y_train)\n",
    "print_grid_search_info(grid_linearSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_micro = 0.9057\n",
      "recall_score = 0.9054968328127582\n",
      "precision_score = 0.9053354655929421\n"
     ]
    }
   ],
   "source": [
    "Y_pred_linSVC = grid_linearSVC.predict(X_test)\n",
    "print_metrics(Y_test, Y_pred_linSVC)\n",
    "save_model('./models/tfidf_lin_svc.pkl', grid_linearSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_IDF_trash = vectorizer.fit_transform(train_removed_trash).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(TF_IDF_trash, Y, test_size=0.25, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters_logreg = {\n",
    "#     'penalty': ['l1', 'l2'],\n",
    "#     'C': [0.01, 0.1, 0.5, 1.0, 10.0],\n",
    "#     'solver': ['lbfgs', 'liblinear'],\n",
    "#     'max_iter': [100, 500]\n",
    "# }\n",
    "\n",
    "# grid_log = get_gridsearch_for_model(LogisticRegression(), parameters_logreg)\n",
    "\n",
    "# grid_log.fit(X_train, Y_train)\n",
    "# print_grid_search_info(grid_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_pred_logreg = grid_log.predict(X_test)\n",
    "# print_metrics(Y_test, Y_pred_logreg)\n",
    "# save_model('./models/tfidf_log_reg_trash.pkl', grid_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_linSVC = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'loss': ['hinge', 'squared_hinge'],\n",
    "    'C': np.linspace(0.001, 0.1, 5),\n",
    "    'max_iter': [1000, 3000, 5000],\n",
    "    'dual':[True]\n",
    "}\n",
    "\n",
    "grid_linearSVC = get_gridsearch_for_model(LinearSVC(), parameters_linSVC)\n",
    "\n",
    "grid_linearSVC.fit(X_train, Y_train)\n",
    "print_grid_search_info(grid_linearSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_micro = 0.9035333333333334\n",
      "recall_score = 0.9033344208409184\n",
      "precision_score = 0.903135971056928\n"
     ]
    }
   ],
   "source": [
    "Y_pred_linSVC = grid_linearSVC.predict(X_test)\n",
    "print_metrics(Y_test, Y_pred_linSVC)\n",
    "save_model('./models/tfidf_lin_svc_trash.pkl', grid_linearSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_IDF_digits = vectorizer.fit_transform(train_removed_digits).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(TF_IDF_digits, Y, test_size=0.25, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters_logreg = {\n",
    "#     'penalty': ['l1', 'l2'],\n",
    "#     'C': [0.01, 0.1, 0.5, 1.0, 10.0],\n",
    "#     'solver': ['lbfgs', 'liblinear'],\n",
    "#     'max_iter': [100, 500]\n",
    "# }\n",
    "\n",
    "# grid_log = get_gridsearch_for_model(LogisticRegression(), parameters_logreg)\n",
    "\n",
    "# grid_log.fit(X_train, Y_train)\n",
    "# print_grid_search_info(grid_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_pred_logreg = grid_log.predict(X_test)\n",
    "# print_metrics(Y_test, Y_pred_logreg)\n",
    "# save_model('./models/tfidf_log_reg_digits.pkl', grid_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_linSVC = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'loss': ['hinge', 'squared_hinge'],\n",
    "    'C': np.linspace(0.001, 0.1, 5),\n",
    "    'max_iter': [1000, 3000, 5000],\n",
    "    'dual':[True]\n",
    "}\n",
    "\n",
    "grid_linearSVC = get_gridsearch_for_model(LinearSVC(), parameters_linSVC)\n",
    "\n",
    "grid_linearSVC.fit(X_train, Y_train)\n",
    "print_grid_search_info(grid_linearSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_micro = 0.9052666666666667\n",
      "recall_score = 0.9050644250852479\n",
      "precision_score = 0.9048826648675069\n"
     ]
    }
   ],
   "source": [
    "Y_pred_linSVC = grid_linearSVC.predict(X_test)\n",
    "print_metrics(Y_test, Y_pred_linSVC)\n",
    "save_model('./models/tfidf_lin_svc_digits.pkl', grid_linearSVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization and try over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_removed_stopwords_copy = [' '.join([lemmatizer.lemmatize(word, pos=\"n\") for word in text.split()]) for text in train_removed_stopwords]\n",
    "train_removed_stopwords_copy = [' '.join([lemmatizer.lemmatize(word, pos=\"a\") for word in text.split()]) for text in train_removed_stopwords]\n",
    "train_removed_stopwords_copy = [' '.join([lemmatizer.lemmatize(word, pos=\"v\") for word in text.split()]) for text in train_removed_stopwords]\n",
    "train_removed_stopwords_copy = [' '.join([lemmatizer.lemmatize(word, pos=\"r\") for word in text.split()]) for text in train_removed_stopwords]\n",
    "train_removed_stopwords_copy = [' '.join([lemmatizer.lemmatize(word, pos=\"s\") for word in text.split()]) for text in train_removed_stopwords]\n",
    "\n",
    "train_removed_trash_copy = [' '.join([lemmatizer.lemmatize(word, pos=\"n\") for word in text.split()]) for text in train_removed_trash]\n",
    "train_removed_trash_copy = [' '.join([lemmatizer.lemmatize(word, pos=\"a\") for word in text.split()]) for text in train_removed_trash]\n",
    "train_removed_trash_copy = [' '.join([lemmatizer.lemmatize(word, pos=\"v\") for word in text.split()]) for text in train_removed_trash]\n",
    "train_removed_trash_copy = [' '.join([lemmatizer.lemmatize(word, pos=\"r\") for word in text.split()]) for text in train_removed_trash]\n",
    "train_removed_trash_copy = [' '.join([lemmatizer.lemmatize(word, pos=\"s\") for word in text.split()]) for text in train_removed_trash]\n",
    "\n",
    "train_removed_digits_copy = [' '.join([lemmatizer.lemmatize(word, pos=\"n\") for word in text.split()]) for text in train_removed_digits]\n",
    "train_removed_digits_copy = [' '.join([lemmatizer.lemmatize(word, pos=\"a\") for word in text.split()]) for text in train_removed_digits]\n",
    "train_removed_digits_copy = [' '.join([lemmatizer.lemmatize(word, pos=\"v\") for word in text.split()]) for text in train_removed_digits]\n",
    "train_removed_digits_copy = [' '.join([lemmatizer.lemmatize(word, pos=\"r\") for word in text.split()]) for text in train_removed_digits]\n",
    "train_removed_digits_copy = [' '.join([lemmatizer.lemmatize(word, pos=\"s\") for word in text.split()]) for text in train_removed_digits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words=stop_words.get_stop_words('en'), max_features=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = train_dataset[\"Class Index\"]\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/.local/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aren', 'can', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'let', 'll', 'mustn', 're', 'shan', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "CVect_stopwords = vectorizer.fit_transform(train_removed_stopwords_copy).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(CVect_stopwords, Y, test_size=0.25, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_linSVC = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'loss': ['hinge', 'squared_hinge'],\n",
    "    'C': np.linspace(0.001, 0.1, 5),\n",
    "    'max_iter': [1000, 3000, 5000],\n",
    "    'dual':[True]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_linearSVC = get_gridsearch_for_model(LinearSVC(), parameters_linSVC)\n",
    "\n",
    "grid_linearSVC.fit(X_train, Y_train)\n",
    "print_grid_search_info(grid_linearSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_micro = 0.9045333333333333\n",
      "recall_score = 0.9043353591136335\n",
      "precision_score = 0.9042743026896476\n"
     ]
    }
   ],
   "source": [
    "Y_pred_linSVC = grid_linearSVC.predict(X_test)\n",
    "print_metrics(Y_test, Y_pred_linSVC)\n",
    "save_model('./models/lemmat_lin_svc.pkl', grid_linearSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/.local/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aren', 'can', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'let', 'll', 'mustn', 're', 'shan', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "CVect_trash = vectorizer.fit_transform(train_removed_trash_copy).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(CVect_trash, Y, test_size=0.25, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 60 candidates, totalling 180 fits\n",
      "[CV 1/3] END C=0.001, dual=True, loss=hinge, max_iter=1000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   3.8s\n",
      "[CV 2/3] END C=0.001, dual=True, loss=hinge, max_iter=1000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   3.1s\n",
      "[CV 3/3] END C=0.001, dual=True, loss=hinge, max_iter=1000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   3.0s\n",
      "[CV 1/3] END C=0.001, dual=True, loss=hinge, max_iter=1000, penalty=l2; accuracy: (test=0.860) f1_micro: (test=0.860) recall_macro: (test=0.860) total time=   6.3s\n",
      "[CV 2/3] END C=0.001, dual=True, loss=hinge, max_iter=1000, penalty=l2; accuracy: (test=0.859) f1_micro: (test=0.859) recall_macro: (test=0.859) total time=   5.5s\n",
      "[CV 3/3] END C=0.001, dual=True, loss=hinge, max_iter=1000, penalty=l2; accuracy: (test=0.860) f1_micro: (test=0.860) recall_macro: (test=0.860) total time=   5.2s\n",
      "[CV 1/3] END C=0.001, dual=True, loss=hinge, max_iter=3000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   3.3s\n",
      "[CV 2/3] END C=0.001, dual=True, loss=hinge, max_iter=3000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   4.0s\n",
      "[CV 3/3] END C=0.001, dual=True, loss=hinge, max_iter=3000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   3.5s\n",
      "[CV 1/3] END C=0.001, dual=True, loss=hinge, max_iter=3000, penalty=l2; accuracy: (test=0.860) f1_micro: (test=0.860) recall_macro: (test=0.860) total time=   6.4s\n",
      "[CV 2/3] END C=0.001, dual=True, loss=hinge, max_iter=3000, penalty=l2; accuracy: (test=0.859) f1_micro: (test=0.859) recall_macro: (test=0.859) total time=   5.3s\n",
      "[CV 3/3] END C=0.001, dual=True, loss=hinge, max_iter=3000, penalty=l2; accuracy: (test=0.860) f1_micro: (test=0.860) recall_macro: (test=0.860) total time=   5.8s\n",
      "[CV 1/3] END C=0.001, dual=True, loss=hinge, max_iter=5000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.4s\n",
      "[CV 2/3] END C=0.001, dual=True, loss=hinge, max_iter=5000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.8s\n",
      "[CV 3/3] END C=0.001, dual=True, loss=hinge, max_iter=5000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.9s\n",
      "[CV 1/3] END C=0.001, dual=True, loss=hinge, max_iter=5000, penalty=l2; accuracy: (test=0.860) f1_micro: (test=0.860) recall_macro: (test=0.860) total time=   5.7s\n",
      "[CV 2/3] END C=0.001, dual=True, loss=hinge, max_iter=5000, penalty=l2; accuracy: (test=0.859) f1_micro: (test=0.859) recall_macro: (test=0.859) total time=   7.6s\n",
      "[CV 3/3] END C=0.001, dual=True, loss=hinge, max_iter=5000, penalty=l2; accuracy: (test=0.860) f1_micro: (test=0.860) recall_macro: (test=0.860) total time=   5.8s\n",
      "[CV 1/3] END C=0.001, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.7s\n",
      "[CV 2/3] END C=0.001, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   3.3s\n",
      "[CV 3/3] END C=0.001, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   4.0s\n",
      "[CV 1/3] END C=0.001, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; accuracy: (test=0.878) f1_micro: (test=0.878) recall_macro: (test=0.878) total time=   5.3s\n",
      "[CV 2/3] END C=0.001, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; accuracy: (test=0.878) f1_micro: (test=0.878) recall_macro: (test=0.878) total time=   5.3s\n",
      "[CV 3/3] END C=0.001, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; accuracy: (test=0.879) f1_micro: (test=0.879) recall_macro: (test=0.879) total time=   5.1s\n",
      "[CV 1/3] END C=0.001, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   3.0s\n",
      "[CV 2/3] END C=0.001, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.8s\n",
      "[CV 3/3] END C=0.001, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.7s\n",
      "[CV 1/3] END C=0.001, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; accuracy: (test=0.878) f1_micro: (test=0.878) recall_macro: (test=0.878) total time=   6.7s\n",
      "[CV 2/3] END C=0.001, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; accuracy: (test=0.878) f1_micro: (test=0.878) recall_macro: (test=0.878) total time=   5.7s\n",
      "[CV 3/3] END C=0.001, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; accuracy: (test=0.879) f1_micro: (test=0.879) recall_macro: (test=0.879) total time=   5.6s\n",
      "[CV 1/3] END C=0.001, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.7s\n",
      "[CV 2/3] END C=0.001, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   3.2s\n",
      "[CV 3/3] END C=0.001, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.8s\n",
      "[CV 1/3] END C=0.001, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; accuracy: (test=0.878) f1_micro: (test=0.878) recall_macro: (test=0.878) total time=   9.5s\n",
      "[CV 2/3] END C=0.001, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; accuracy: (test=0.878) f1_micro: (test=0.878) recall_macro: (test=0.878) total time=   8.4s\n",
      "[CV 3/3] END C=0.001, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; accuracy: (test=0.879) f1_micro: (test=0.879) recall_macro: (test=0.879) total time=   5.7s\n",
      "[CV 1/3] END C=0.025750000000000002, dual=True, loss=hinge, max_iter=1000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.2s\n",
      "[CV 2/3] END C=0.025750000000000002, dual=True, loss=hinge, max_iter=1000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.4s\n",
      "[CV 3/3] END C=0.025750000000000002, dual=True, loss=hinge, max_iter=1000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.1s\n",
      "[CV 1/3] END C=0.025750000000000002, dual=True, loss=hinge, max_iter=1000, penalty=l2; accuracy: (test=0.899) f1_micro: (test=0.899) recall_macro: (test=0.899) total time=   5.7s\n",
      "[CV 2/3] END C=0.025750000000000002, dual=True, loss=hinge, max_iter=1000, penalty=l2; accuracy: (test=0.899) f1_micro: (test=0.899) recall_macro: (test=0.899) total time=   5.5s\n",
      "[CV 3/3] END C=0.025750000000000002, dual=True, loss=hinge, max_iter=1000, penalty=l2; accuracy: (test=0.900) f1_micro: (test=0.900) recall_macro: (test=0.900) total time=   5.7s\n",
      "[CV 1/3] END C=0.025750000000000002, dual=True, loss=hinge, max_iter=3000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.3s\n",
      "[CV 2/3] END C=0.025750000000000002, dual=True, loss=hinge, max_iter=3000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.3s\n",
      "[CV 3/3] END C=0.025750000000000002, dual=True, loss=hinge, max_iter=3000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.6s\n",
      "[CV 1/3] END C=0.025750000000000002, dual=True, loss=hinge, max_iter=3000, penalty=l2; accuracy: (test=0.899) f1_micro: (test=0.899) recall_macro: (test=0.899) total time=   5.7s\n",
      "[CV 2/3] END C=0.025750000000000002, dual=True, loss=hinge, max_iter=3000, penalty=l2; accuracy: (test=0.899) f1_micro: (test=0.899) recall_macro: (test=0.899) total time=   5.7s\n",
      "[CV 3/3] END C=0.025750000000000002, dual=True, loss=hinge, max_iter=3000, penalty=l2; accuracy: (test=0.900) f1_micro: (test=0.900) recall_macro: (test=0.900) total time=   5.2s\n",
      "[CV 1/3] END C=0.025750000000000002, dual=True, loss=hinge, max_iter=5000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.8s\n",
      "[CV 2/3] END C=0.025750000000000002, dual=True, loss=hinge, max_iter=5000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.7s\n",
      "[CV 3/3] END C=0.025750000000000002, dual=True, loss=hinge, max_iter=5000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   3.9s\n",
      "[CV 1/3] END C=0.025750000000000002, dual=True, loss=hinge, max_iter=5000, penalty=l2; accuracy: (test=0.899) f1_micro: (test=0.899) recall_macro: (test=0.899) total time=   5.1s\n",
      "[CV 2/3] END C=0.025750000000000002, dual=True, loss=hinge, max_iter=5000, penalty=l2; accuracy: (test=0.899) f1_micro: (test=0.899) recall_macro: (test=0.899) total time=   5.4s\n",
      "[CV 3/3] END C=0.025750000000000002, dual=True, loss=hinge, max_iter=5000, penalty=l2; accuracy: (test=0.900) f1_micro: (test=0.900) recall_macro: (test=0.900) total time=   5.2s\n",
      "[CV 1/3] END C=0.025750000000000002, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.5s\n",
      "[CV 2/3] END C=0.025750000000000002, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.1s\n",
      "[CV 3/3] END C=0.025750000000000002, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.0s\n",
      "[CV 1/3] END C=0.025750000000000002, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; accuracy: (test=0.898) f1_micro: (test=0.898) recall_macro: (test=0.898) total time=   6.6s\n",
      "[CV 2/3] END C=0.025750000000000002, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; accuracy: (test=0.900) f1_micro: (test=0.900) recall_macro: (test=0.900) total time=   5.3s\n",
      "[CV 3/3] END C=0.025750000000000002, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; accuracy: (test=0.900) f1_micro: (test=0.900) recall_macro: (test=0.900) total time=   6.1s\n",
      "[CV 1/3] END C=0.025750000000000002, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.5s\n",
      "[CV 2/3] END C=0.025750000000000002, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.4s\n",
      "[CV 3/3] END C=0.025750000000000002, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.5s\n",
      "[CV 1/3] END C=0.025750000000000002, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; accuracy: (test=0.898) f1_micro: (test=0.898) recall_macro: (test=0.898) total time=   5.3s\n",
      "[CV 2/3] END C=0.025750000000000002, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; accuracy: (test=0.900) f1_micro: (test=0.900) recall_macro: (test=0.900) total time=   5.4s\n",
      "[CV 3/3] END C=0.025750000000000002, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; accuracy: (test=0.900) f1_micro: (test=0.900) recall_macro: (test=0.900) total time=   5.7s\n",
      "[CV 1/3] END C=0.025750000000000002, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.2s\n",
      "[CV 2/3] END C=0.025750000000000002, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.1s\n",
      "[CV 3/3] END C=0.025750000000000002, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.0s\n",
      "[CV 1/3] END C=0.025750000000000002, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; accuracy: (test=0.898) f1_micro: (test=0.898) recall_macro: (test=0.898) total time=   5.7s\n",
      "[CV 2/3] END C=0.025750000000000002, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; accuracy: (test=0.900) f1_micro: (test=0.900) recall_macro: (test=0.900) total time=   5.2s\n",
      "[CV 3/3] END C=0.025750000000000002, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; accuracy: (test=0.900) f1_micro: (test=0.900) recall_macro: (test=0.900) total time=   4.9s\n",
      "[CV 1/3] END C=0.0505, dual=True, loss=hinge, max_iter=1000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.1s\n",
      "[CV 2/3] END C=0.0505, dual=True, loss=hinge, max_iter=1000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.1s\n",
      "[CV 3/3] END C=0.0505, dual=True, loss=hinge, max_iter=1000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.0505, dual=True, loss=hinge, max_iter=1000, penalty=l2; accuracy: (test=0.900) f1_micro: (test=0.900) recall_macro: (test=0.900) total time=   5.6s\n",
      "[CV 2/3] END C=0.0505, dual=True, loss=hinge, max_iter=1000, penalty=l2; accuracy: (test=0.900) f1_micro: (test=0.900) recall_macro: (test=0.900) total time=   5.0s\n",
      "[CV 3/3] END C=0.0505, dual=True, loss=hinge, max_iter=1000, penalty=l2; accuracy: (test=0.901) f1_micro: (test=0.901) recall_macro: (test=0.901) total time=   5.4s\n",
      "[CV 1/3] END C=0.0505, dual=True, loss=hinge, max_iter=3000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.3s\n",
      "[CV 2/3] END C=0.0505, dual=True, loss=hinge, max_iter=3000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.2s\n",
      "[CV 3/3] END C=0.0505, dual=True, loss=hinge, max_iter=3000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.8s\n",
      "[CV 1/3] END C=0.0505, dual=True, loss=hinge, max_iter=3000, penalty=l2; accuracy: (test=0.900) f1_micro: (test=0.900) recall_macro: (test=0.900) total time=   5.6s\n",
      "[CV 2/3] END C=0.0505, dual=True, loss=hinge, max_iter=3000, penalty=l2; accuracy: (test=0.900) f1_micro: (test=0.900) recall_macro: (test=0.900) total time=   5.9s\n",
      "[CV 3/3] END C=0.0505, dual=True, loss=hinge, max_iter=3000, penalty=l2; accuracy: (test=0.901) f1_micro: (test=0.901) recall_macro: (test=0.901) total time=   5.4s\n",
      "[CV 1/3] END C=0.0505, dual=True, loss=hinge, max_iter=5000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.3s\n",
      "[CV 2/3] END C=0.0505, dual=True, loss=hinge, max_iter=5000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.9s\n",
      "[CV 3/3] END C=0.0505, dual=True, loss=hinge, max_iter=5000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.4s\n",
      "[CV 1/3] END C=0.0505, dual=True, loss=hinge, max_iter=5000, penalty=l2; accuracy: (test=0.900) f1_micro: (test=0.900) recall_macro: (test=0.900) total time=   5.9s\n",
      "[CV 2/3] END C=0.0505, dual=True, loss=hinge, max_iter=5000, penalty=l2; accuracy: (test=0.900) f1_micro: (test=0.900) recall_macro: (test=0.900) total time=   5.6s\n",
      "[CV 3/3] END C=0.0505, dual=True, loss=hinge, max_iter=5000, penalty=l2; accuracy: (test=0.901) f1_micro: (test=0.901) recall_macro: (test=0.901) total time=   5.4s\n",
      "[CV 1/3] END C=0.0505, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   3.0s\n",
      "[CV 2/3] END C=0.0505, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.8s\n",
      "[CV 3/3] END C=0.0505, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.5s\n",
      "[CV 1/3] END C=0.0505, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; accuracy: (test=0.896) f1_micro: (test=0.896) recall_macro: (test=0.896) total time=   6.5s\n",
      "[CV 2/3] END C=0.0505, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; accuracy: (test=0.899) f1_micro: (test=0.899) recall_macro: (test=0.899) total time=   5.4s\n",
      "[CV 3/3] END C=0.0505, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; accuracy: (test=0.900) f1_micro: (test=0.900) recall_macro: (test=0.900) total time=   7.2s\n",
      "[CV 1/3] END C=0.0505, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.6s\n",
      "[CV 2/3] END C=0.0505, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.5s\n",
      "[CV 3/3] END C=0.0505, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.8s\n",
      "[CV 1/3] END C=0.0505, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; accuracy: (test=0.896) f1_micro: (test=0.896) recall_macro: (test=0.896) total time=   6.8s\n",
      "[CV 2/3] END C=0.0505, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; accuracy: (test=0.899) f1_micro: (test=0.899) recall_macro: (test=0.899) total time=   5.6s\n",
      "[CV 3/3] END C=0.0505, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; accuracy: (test=0.900) f1_micro: (test=0.900) recall_macro: (test=0.900) total time=   7.0s\n",
      "[CV 1/3] END C=0.0505, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.5s\n",
      "[CV 2/3] END C=0.0505, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.4s\n",
      "[CV 3/3] END C=0.0505, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.5s\n",
      "[CV 1/3] END C=0.0505, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; accuracy: (test=0.896) f1_micro: (test=0.896) recall_macro: (test=0.896) total time=   5.8s\n",
      "[CV 2/3] END C=0.0505, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; accuracy: (test=0.899) f1_micro: (test=0.899) recall_macro: (test=0.899) total time=   6.3s\n",
      "[CV 3/3] END C=0.0505, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; accuracy: (test=0.900) f1_micro: (test=0.900) recall_macro: (test=0.900) total time=   5.3s\n",
      "[CV 1/3] END C=0.07525000000000001, dual=True, loss=hinge, max_iter=1000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.8s\n",
      "[CV 2/3] END C=0.07525000000000001, dual=True, loss=hinge, max_iter=1000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   3.4s\n",
      "[CV 3/3] END C=0.07525000000000001, dual=True, loss=hinge, max_iter=1000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.4s\n",
      "[CV 1/3] END C=0.07525000000000001, dual=True, loss=hinge, max_iter=1000, penalty=l2; accuracy: (test=0.898) f1_micro: (test=0.898) recall_macro: (test=0.898) total time=   5.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=0.07525000000000001, dual=True, loss=hinge, max_iter=1000, penalty=l2; accuracy: (test=0.900) f1_micro: (test=0.900) recall_macro: (test=0.900) total time=   5.4s\n",
      "[CV 3/3] END C=0.07525000000000001, dual=True, loss=hinge, max_iter=1000, penalty=l2; accuracy: (test=0.901) f1_micro: (test=0.901) recall_macro: (test=0.901) total time=   6.3s\n",
      "[CV 1/3] END C=0.07525000000000001, dual=True, loss=hinge, max_iter=3000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.2s\n",
      "[CV 2/3] END C=0.07525000000000001, dual=True, loss=hinge, max_iter=3000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.3s\n",
      "[CV 3/3] END C=0.07525000000000001, dual=True, loss=hinge, max_iter=3000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.5s\n",
      "[CV 1/3] END C=0.07525000000000001, dual=True, loss=hinge, max_iter=3000, penalty=l2; accuracy: (test=0.898) f1_micro: (test=0.898) recall_macro: (test=0.898) total time=   5.7s\n",
      "[CV 2/3] END C=0.07525000000000001, dual=True, loss=hinge, max_iter=3000, penalty=l2; accuracy: (test=0.900) f1_micro: (test=0.900) recall_macro: (test=0.900) total time=   5.2s\n",
      "[CV 3/3] END C=0.07525000000000001, dual=True, loss=hinge, max_iter=3000, penalty=l2; accuracy: (test=0.901) f1_micro: (test=0.901) recall_macro: (test=0.901) total time=   5.4s\n",
      "[CV 1/3] END C=0.07525000000000001, dual=True, loss=hinge, max_iter=5000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.2s\n",
      "[CV 2/3] END C=0.07525000000000001, dual=True, loss=hinge, max_iter=5000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.1s\n",
      "[CV 3/3] END C=0.07525000000000001, dual=True, loss=hinge, max_iter=5000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.1s\n",
      "[CV 1/3] END C=0.07525000000000001, dual=True, loss=hinge, max_iter=5000, penalty=l2; accuracy: (test=0.898) f1_micro: (test=0.898) recall_macro: (test=0.898) total time=   5.2s\n",
      "[CV 2/3] END C=0.07525000000000001, dual=True, loss=hinge, max_iter=5000, penalty=l2; accuracy: (test=0.900) f1_micro: (test=0.900) recall_macro: (test=0.900) total time=   5.1s\n",
      "[CV 3/3] END C=0.07525000000000001, dual=True, loss=hinge, max_iter=5000, penalty=l2; accuracy: (test=0.901) f1_micro: (test=0.901) recall_macro: (test=0.901) total time=   5.5s\n",
      "[CV 1/3] END C=0.07525000000000001, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.2s\n",
      "[CV 2/3] END C=0.07525000000000001, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.7s\n",
      "[CV 3/3] END C=0.07525000000000001, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.0s\n",
      "[CV 1/3] END C=0.07525000000000001, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; accuracy: (test=0.894) f1_micro: (test=0.894) recall_macro: (test=0.894) total time=   5.2s\n",
      "[CV 2/3] END C=0.07525000000000001, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; accuracy: (test=0.896) f1_micro: (test=0.896) recall_macro: (test=0.896) total time=   5.6s\n",
      "[CV 3/3] END C=0.07525000000000001, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; accuracy: (test=0.898) f1_micro: (test=0.898) recall_macro: (test=0.898) total time=   5.3s\n",
      "[CV 1/3] END C=0.07525000000000001, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.2s\n",
      "[CV 2/3] END C=0.07525000000000001, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.1s\n",
      "[CV 3/3] END C=0.07525000000000001, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.0s\n",
      "[CV 1/3] END C=0.07525000000000001, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; accuracy: (test=0.894) f1_micro: (test=0.894) recall_macro: (test=0.894) total time=   5.5s\n",
      "[CV 2/3] END C=0.07525000000000001, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; accuracy: (test=0.896) f1_micro: (test=0.896) recall_macro: (test=0.896) total time=   7.6s\n",
      "[CV 3/3] END C=0.07525000000000001, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; accuracy: (test=0.898) f1_micro: (test=0.898) recall_macro: (test=0.898) total time=   6.1s\n",
      "[CV 1/3] END C=0.07525000000000001, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.1s\n",
      "[CV 2/3] END C=0.07525000000000001, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.4s\n",
      "[CV 3/3] END C=0.07525000000000001, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.2s\n",
      "[CV 1/3] END C=0.07525000000000001, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; accuracy: (test=0.894) f1_micro: (test=0.894) recall_macro: (test=0.894) total time=   5.1s\n",
      "[CV 2/3] END C=0.07525000000000001, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; accuracy: (test=0.896) f1_micro: (test=0.896) recall_macro: (test=0.896) total time=   5.3s\n",
      "[CV 3/3] END C=0.07525000000000001, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; accuracy: (test=0.898) f1_micro: (test=0.898) recall_macro: (test=0.898) total time=   5.6s\n",
      "[CV 1/3] END C=0.1, dual=True, loss=hinge, max_iter=1000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.2s\n",
      "[CV 2/3] END C=0.1, dual=True, loss=hinge, max_iter=1000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.3s\n",
      "[CV 3/3] END C=0.1, dual=True, loss=hinge, max_iter=1000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.1, dual=True, loss=hinge, max_iter=1000, penalty=l2; accuracy: (test=0.898) f1_micro: (test=0.898) recall_macro: (test=0.898) total time=   6.5s\n",
      "[CV 2/3] END C=0.1, dual=True, loss=hinge, max_iter=1000, penalty=l2; accuracy: (test=0.900) f1_micro: (test=0.900) recall_macro: (test=0.900) total time=   5.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.1, dual=True, loss=hinge, max_iter=1000, penalty=l2; accuracy: (test=0.901) f1_micro: (test=0.901) recall_macro: (test=0.901) total time=   5.8s\n",
      "[CV 1/3] END C=0.1, dual=True, loss=hinge, max_iter=3000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.1s\n",
      "[CV 2/3] END C=0.1, dual=True, loss=hinge, max_iter=3000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.1s\n",
      "[CV 3/3] END C=0.1, dual=True, loss=hinge, max_iter=3000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.0s\n",
      "[CV 1/3] END C=0.1, dual=True, loss=hinge, max_iter=3000, penalty=l2; accuracy: (test=0.898) f1_micro: (test=0.898) recall_macro: (test=0.898) total time=   6.7s\n",
      "[CV 2/3] END C=0.1, dual=True, loss=hinge, max_iter=3000, penalty=l2; accuracy: (test=0.900) f1_micro: (test=0.900) recall_macro: (test=0.900) total time=   5.9s\n",
      "[CV 3/3] END C=0.1, dual=True, loss=hinge, max_iter=3000, penalty=l2; accuracy: (test=0.901) f1_micro: (test=0.901) recall_macro: (test=0.901) total time=   6.3s\n",
      "[CV 1/3] END C=0.1, dual=True, loss=hinge, max_iter=5000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.4s\n",
      "[CV 2/3] END C=0.1, dual=True, loss=hinge, max_iter=5000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   3.0s\n",
      "[CV 3/3] END C=0.1, dual=True, loss=hinge, max_iter=5000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.3s\n",
      "[CV 1/3] END C=0.1, dual=True, loss=hinge, max_iter=5000, penalty=l2; accuracy: (test=0.898) f1_micro: (test=0.898) recall_macro: (test=0.898) total time=   6.8s\n",
      "[CV 2/3] END C=0.1, dual=True, loss=hinge, max_iter=5000, penalty=l2; accuracy: (test=0.900) f1_micro: (test=0.900) recall_macro: (test=0.900) total time=   6.4s\n",
      "[CV 3/3] END C=0.1, dual=True, loss=hinge, max_iter=5000, penalty=l2; accuracy: (test=0.901) f1_micro: (test=0.901) recall_macro: (test=0.901) total time=   5.5s\n",
      "[CV 1/3] END C=0.1, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.2s\n",
      "[CV 2/3] END C=0.1, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.6s\n",
      "[CV 3/3] END C=0.1, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.9s\n",
      "[CV 1/3] END C=0.1, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; accuracy: (test=0.892) f1_micro: (test=0.892) recall_macro: (test=0.892) total time=   5.8s\n",
      "[CV 2/3] END C=0.1, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; accuracy: (test=0.895) f1_micro: (test=0.895) recall_macro: (test=0.895) total time=   5.5s\n",
      "[CV 3/3] END C=0.1, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; accuracy: (test=0.895) f1_micro: (test=0.895) recall_macro: (test=0.895) total time=   6.1s\n",
      "[CV 1/3] END C=0.1, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.1s\n",
      "[CV 2/3] END C=0.1, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.0s\n",
      "[CV 3/3] END C=0.1, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.4s\n",
      "[CV 1/3] END C=0.1, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; accuracy: (test=0.892) f1_micro: (test=0.892) recall_macro: (test=0.892) total time=   6.2s\n",
      "[CV 2/3] END C=0.1, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; accuracy: (test=0.895) f1_micro: (test=0.895) recall_macro: (test=0.895) total time=   5.6s\n",
      "[CV 3/3] END C=0.1, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; accuracy: (test=0.895) f1_micro: (test=0.895) recall_macro: (test=0.895) total time=   5.5s\n",
      "[CV 1/3] END C=0.1, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.2s\n",
      "[CV 2/3] END C=0.1, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.0s\n",
      "[CV 3/3] END C=0.1, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.6s\n",
      "[CV 1/3] END C=0.1, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; accuracy: (test=0.892) f1_micro: (test=0.892) recall_macro: (test=0.892) total time=   5.8s\n",
      "[CV 2/3] END C=0.1, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; accuracy: (test=0.895) f1_micro: (test=0.895) recall_macro: (test=0.895) total time=   5.6s\n",
      "[CV 3/3] END C=0.1, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; accuracy: (test=0.895) f1_micro: (test=0.895) recall_macro: (test=0.895) total time=   5.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "90 fits failed out of a total of 180.\n",
      "The score on these train-test partitions for these parameters will be set to 0.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/habkaffee/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/habkaffee/.local/lib/python3.10/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/home/habkaffee/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 326, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/habkaffee/.local/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1229, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/habkaffee/.local/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1060, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/habkaffee/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/habkaffee/.local/lib/python3.10/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/home/habkaffee/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 326, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/habkaffee/.local/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1229, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/habkaffee/.local/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1060, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator -> LinearSVC(C=0.0505, dual=True, loss='hinge')\n",
      "Best Score -> 0.9001444444444444\n",
      "Best Parameters -> {'C': 0.0505, 'dual': True, 'loss': 'hinge', 'max_iter': 1000, 'penalty': 'l2'}\n",
      "Best index -> 25\n"
     ]
    }
   ],
   "source": [
    "grid_linearSVC = get_gridsearch_for_model(LinearSVC(), parameters_linSVC)\n",
    "\n",
    "grid_linearSVC.fit(X_train, Y_train)\n",
    "print_grid_search_info(grid_linearSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_micro = 0.9031333333333333\n",
      "recall_score = 0.9029243615170612\n",
      "precision_score = 0.9027782087428682\n"
     ]
    }
   ],
   "source": [
    "Y_pred_linSVC = grid_linearSVC.predict(X_test)\n",
    "print_metrics(Y_test, Y_pred_linSVC)\n",
    "save_model('./models/lemmat_lin_svc_trash.pkl', grid_linearSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "CVect_digits = vectorizer.fit_transform(train_removed_digits_copy).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(CVect_digits, Y, test_size=0.25, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_linearSVC = get_gridsearch_for_model(LinearSVC(), parameters_linSVC)\n",
    "\n",
    "grid_linearSVC.fit(X_train, Y_train)\n",
    "print_grid_search_info(grid_linearSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_micro = 0.9043666666666667\n",
      "recall_score = 0.9041685957174672\n",
      "precision_score = 0.9040971142191401\n"
     ]
    }
   ],
   "source": [
    "Y_pred_linSVC = grid_linearSVC.predict(X_test)\n",
    "print_metrics(Y_test, Y_pred_linSVC)\n",
    "save_model('./models/lemmat_lin_svc_digits.pkl', grid_linearSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=stop_words.get_stop_words(\"en\"), max_features=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = train_dataset[\"Class Index\"]\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/.local/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aren', 'can', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'let', 'll', 'mustn', 're', 'shan', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "TF_IDF_stopwords = vectorizer.fit_transform(train_removed_stopwords_copy).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_linSVC = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'loss': ['hinge', 'squared_hinge'],\n",
    "    'C': np.linspace(0.001, 0.1, 5),\n",
    "    'max_iter': [1000, 3000, 5000],\n",
    "    'dual':[True]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(TF_IDF_stopwords, Y, test_size=0.25, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_linearSVC = get_gridsearch_for_model(LinearSVC(), parameters_linSVC)\n",
    "\n",
    "grid_linearSVC.fit(X_train, Y_train)\n",
    "print_grid_search_info(grid_linearSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_micro = 0.9052333333333333\n",
      "recall_score = 0.9050308774115083\n",
      "precision_score = 0.9048689336645132\n"
     ]
    }
   ],
   "source": [
    "Y_pred_linSVC = grid_linearSVC.predict(X_test)\n",
    "print_metrics(Y_test, Y_pred_linSVC)\n",
    "save_model('./models/lemmat_tfidf_lin_svc.pkl', grid_linearSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_IDF_trash = vectorizer.fit_transform(train_removed_trash_copy).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(TF_IDF_trash, Y, test_size=0.25, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_linearSVC = get_gridsearch_for_model(LinearSVC(), parameters_linSVC)\n",
    "\n",
    "grid_linearSVC.fit(X_train, Y_train)\n",
    "print_grid_search_info(grid_linearSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_micro = 0.9032333333333333\n",
      "recall_score = 0.9030318371101944\n",
      "precision_score = 0.9028357412750577\n"
     ]
    }
   ],
   "source": [
    "Y_pred_linSVC = grid_linearSVC.predict(X_test)\n",
    "print_metrics(Y_test, Y_pred_linSVC)\n",
    "save_model('./models/lemmat_tfidf_lin_svc_trash.pkl', grid_linearSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_IDF_digits = vectorizer.fit_transform(train_removed_digits_copy).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(TF_IDF_digits, Y, test_size=0.25, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_linearSVC = get_gridsearch_for_model(LinearSVC(), parameters_linSVC)\n",
    "\n",
    "grid_linearSVC.fit(X_train, Y_train)\n",
    "print_grid_search_info(grid_linearSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_micro = 0.9051\n",
      "recall_score = 0.904896421008043\n",
      "precision_score = 0.9047320676323019\n"
     ]
    }
   ],
   "source": [
    "Y_pred_linSVC = grid_linearSVC.predict(X_test)\n",
    "print_metrics(Y_test, Y_pred_linSVC)\n",
    "save_model('./models/lemmat_tfidf_lin_svc_digits.pkl', grid_linearSVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/habkaffee/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_removed_stopwords = [' '.join([stemmer.stem(word) for word in text.split()]) for text in train_removed_stopwords]\n",
    "\n",
    "train_removed_trash = [' '.join([stemmer.stem(word) for word in text.split()]) for text in train_removed_trash]\n",
    "\n",
    "train_removed_digits = [' '.join([stemmer.stem(word) for word in text.split()]) for text in train_removed_digits]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words=stop_words.get_stop_words('en'), max_features=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = train_dataset[\"Class Index\"]\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/.local/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aren', 'can', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'let', 'll', 'mustn', 're', 'shan', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "CVect_stopwords = vectorizer.fit_transform(train_removed_stopwords).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(CVect_stopwords, Y, test_size=0.25, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_linSVC = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'loss': ['hinge', 'squared_hinge'],\n",
    "    'C': np.linspace(0.001, 0.1, 5),\n",
    "    'max_iter': [1000, 3000, 5000],\n",
    "    'dual':[True]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_linearSVC = get_gridsearch_for_model(LinearSVC(), parameters_linSVC)\n",
    "\n",
    "grid_linearSVC.fit(X_train, Y_train)\n",
    "print_grid_search_info(grid_linearSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_micro = 0.9054333333333333\n",
      "recall_score = 0.9052204725721449\n",
      "precision_score = 0.9051306886529678\n"
     ]
    }
   ],
   "source": [
    "Y_pred_linSVC = grid_linearSVC.predict(X_test)\n",
    "print_metrics(Y_test, Y_pred_linSVC)\n",
    "save_model('./models/lemmat_lin_svc.pkl', grid_linearSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "CVect_trash = vectorizer.fit_transform(train_removed_trash).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(CVect_trash, Y, test_size=0.25, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_linearSVC = get_gridsearch_for_model(LinearSVC(), parameters_linSVC)\n",
    "\n",
    "grid_linearSVC.fit(X_train, Y_train)\n",
    "print_grid_search_info(grid_linearSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_micro = 0.9031333333333333\n",
      "recall_score = 0.9029339955089166\n",
      "precision_score = 0.9028637161310636\n"
     ]
    }
   ],
   "source": [
    "Y_pred_linSVC = grid_linearSVC.predict(X_test)\n",
    "print_metrics(Y_test, Y_pred_linSVC)\n",
    "save_model('./models/stem_lin_svc_trash.pkl', grid_linearSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "CVect_digits = vectorizer.fit_transform(train_removed_digits).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(CVect_digits, Y, test_size=0.25, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_linearSVC = get_gridsearch_for_model(LinearSVC(), parameters_linSVC)\n",
    "\n",
    "grid_linearSVC.fit(X_train, Y_train)\n",
    "print_grid_search_info(grid_linearSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_micro = 0.9051666666666667\n",
      "recall_score = 0.9049585600507555\n",
      "precision_score = 0.9048495186429608\n"
     ]
    }
   ],
   "source": [
    "Y_pred_linSVC = grid_linearSVC.predict(X_test)\n",
    "print_metrics(Y_test, Y_pred_linSVC)\n",
    "save_model('./models/stem_lin_svc_digits.pkl', grid_linearSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=stop_words.get_stop_words(\"en\"), max_features=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = train_dataset[\"Class Index\"]\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/.local/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aren', 'can', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'let', 'll', 'mustn', 're', 'shan', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "TF_IDF_stopwords = vectorizer.fit_transform(train_removed_stopwords).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_linSVC = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'loss': ['hinge', 'squared_hinge'],\n",
    "    'C': np.linspace(0.001, 0.1, 5),\n",
    "    'max_iter': [1000, 3000, 5000],\n",
    "    'dual':[True]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(TF_IDF_stopwords, Y, test_size=0.25, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_linearSVC = get_gridsearch_for_model(LinearSVC(), parameters_linSVC)\n",
    "\n",
    "grid_linearSVC.fit(X_train, Y_train)\n",
    "print_grid_search_info(grid_linearSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_micro = 0.9047\n",
      "recall_score = 0.9044897923303211\n",
      "precision_score = 0.9042979141655177\n"
     ]
    }
   ],
   "source": [
    "Y_pred_linSVC = grid_linearSVC.predict(X_test)\n",
    "print_metrics(Y_test, Y_pred_linSVC)\n",
    "save_model('./models/stem_tfidf_lin_svc.pkl', grid_linearSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_IDF_trash = vectorizer.fit_transform(train_removed_trash).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(TF_IDF_trash, Y, test_size=0.25, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_linearSVC = get_gridsearch_for_model(LinearSVC(), parameters_linSVC)\n",
    "\n",
    "grid_linearSVC.fit(X_train, Y_train)\n",
    "print_grid_search_info(grid_linearSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_micro = 0.9018333333333334\n",
      "recall_score = 0.9016271360697213\n",
      "precision_score = 0.9014087459406611\n"
     ]
    }
   ],
   "source": [
    "Y_pred_linSVC = grid_linearSVC.predict(X_test)\n",
    "print_metrics(Y_test, Y_pred_linSVC)\n",
    "save_model('./models/stem_tfidf_lin_svc_trash.pkl', grid_linearSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_IDF_digits = vectorizer.fit_transform(train_removed_digits).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(TF_IDF_digits, Y, test_size=0.25, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_linearSVC = get_gridsearch_for_model(LinearSVC(), parameters_linSVC)\n",
    "\n",
    "grid_linearSVC.fit(X_train, Y_train)\n",
    "print_grid_search_info(grid_linearSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_micro = 0.9052333333333333\n",
      "recall_score = 0.9050254743336412\n",
      "precision_score = 0.9048591958377651\n"
     ]
    }
   ],
   "source": [
    "Y_pred_linSVC = grid_linearSVC.predict(X_test)\n",
    "print_metrics(Y_test, Y_pred_linSVC)\n",
    "save_model('./models/stem_tfidf_lin_svc_digits.pkl', grid_linearSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/.local/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aren', 'can', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'let', 'll', 'mustn', 're', 'shan', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# seed = 42\n",
    "# # vectorizer = TfidfVectorizer(stop_words=stop_words.get_stop_words(\"en\"), max_features=10000)\n",
    "# # TF_IDF_trash = vectorizer.fit_transform(train_removed_trash_copy).toarray()\n",
    "# vectorizer = CountVectorizer(stop_words=stop_words.get_stop_words('en'), max_features=10000)\n",
    "# # CVect_trash = vectorizer.fit_transform(train_removed_trash).toarray()\n",
    "\n",
    "# Y = train_dataset[\"Class Index\"]\n",
    "# vectorized = vectorizer.fit_transform(train_removed_trash).toarray()\n",
    "\n",
    "# X_train, X_test, Y_train, Y_test = train_test_split(vectorized, Y, test_size=0.25, random_state=seed)\n",
    "\n",
    "# # linSVC_best = load_model('./models/lemmat_tfidf_lin_svc_trash.pkl')\n",
    "# logreg = load_model('./models/log_reg_trash.pkl')\n",
    "\n",
    "# Y_pred_logreg = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_metrix_df(metrix, name, f1_micro, recall, precision):\n",
    "    metrix[name] = [f1_micro, recall, precision]\n",
    "\n",
    "all_metrics_df = pd.DataFrame(index=['f1_micro', 'Recall', 'Precision'])\n",
    "\n",
    "fill_metrix_df(all_metrics_df, 'LinearSVC',\n",
    "                f1_score(Y_test, Y_pred_linSVC, average='micro'), \n",
    "                recall_score(Y_test, Y_pred_linSVC, average='macro'), \n",
    "                precision_score(Y_test, Y_pred_linSVC, average='macro'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_conf_matrix(Y_test, Y_pred_linSVC, Y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All metrics are displayed below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LinearSVC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1_micro</th>\n",
       "      <td>0.903133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.902924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.902778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           LinearSVC\n",
       "f1_micro    0.903133\n",
       "Recall      0.902924\n",
       "Precision   0.902778"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7595</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7596</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7597</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7598</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7599</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7600 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0\n",
       "0     4\n",
       "1     3\n",
       "2     3\n",
       "3     2\n",
       "4     1\n",
       "...  ..\n",
       "7595  4\n",
       "7596  4\n",
       "7597  3\n",
       "7598  3\n",
       "7599  2\n",
       "\n",
       "[7600 rows x 1 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_to_submit = pd.read_csv('./data/test.csv')\n",
    "test_dataset_splitted_texts = [line.split('\\n') for line in data_to_submit['Description']]\n",
    "data_to_submit = [' '.join([word if word not in stop_words.get_stop_words('en') else '' for word in text]) for text in test_dataset_splitted_texts]\n",
    "vectorized_data = vectorizer.fit_transform(data_to_submit).toarray()\n",
    "# vectorized_data = vectorizer.fit_transform(data_to_submit).toarray()\n",
    "\n",
    "y_predicted = grid_linearSVC.predict(vectorized_data)\n",
    "with open(\"submission.csv\", 'w+') as f:\n",
    "    f.write(\"ID, Class Index\\n\") \n",
    "    for i, el in enumerate(y_predicted):\n",
    "        f.write(f'{i}, {el}\\n')\n",
    "\n",
    "pd.DataFrame(y_predicted)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e6463d715e1378e337fc3da88af56f170e8b2fc8216e6f94629c44ee68539bbe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
