{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pymorphy2\n",
    "# %pip install nltk\n",
    "# %pip install sklearn\n",
    "# %pip install wordcloud\n",
    "# %pip install stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "import pymorphy2\n",
    "from scipy.sparse import *\n",
    "import stop_words\n",
    "import tqdm\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class Index</th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Wall St. Bears Claw Back Into the Black (Reuters)</td>\n",
       "      <td>Reuters - Short-sellers, Wall Street's dwindli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
       "      <td>Reuters - Private investment firm Carlyle Grou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters)</td>\n",
       "      <td>Reuters - Soaring crude prices plus worries\\ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
       "      <td>Reuters - Authorities have halted oil export\\f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Oil prices soar to all-time record, posing new...</td>\n",
       "      <td>AFP - Tearaway world oil prices, toppling reco...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class Index                                              Title  \\\n",
       "0            3  Wall St. Bears Claw Back Into the Black (Reuters)   \n",
       "1            3  Carlyle Looks Toward Commercial Aerospace (Reu...   \n",
       "2            3    Oil and Economy Cloud Stocks' Outlook (Reuters)   \n",
       "3            3  Iraq Halts Oil Exports from Main Southern Pipe...   \n",
       "4            3  Oil prices soar to all-time record, posing new...   \n",
       "\n",
       "                                         Description  \n",
       "0  Reuters - Short-sellers, Wall Street's dwindli...  \n",
       "1  Reuters - Private investment firm Carlyle Grou...  \n",
       "2  Reuters - Soaring crude prices plus worries\\ab...  \n",
       "3  Reuters - Authorities have halted oil export\\f...  \n",
       "4  AFP - Tearaway world oil prices, toppling reco...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = pd.read_csv(\"data/test.csv\")\n",
    "train_dataset = pd.read_csv(\"data/train.csv\")\n",
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's prepare copies of train dataset with 4 different text cleaning techniques (one method at a time):  \n",
    "- stop words removing\n",
    "- punctuation removing\n",
    "- trash removing\n",
    "- digits removing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reuters - Short-sellers, Wall Street's dwindli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reuters - Private investment firm Carlyle Grou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Reuters - Soaring crude prices plus worries\\ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Reuters - Authorities have halted oil export\\f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFP - Tearaway world oil prices, toppling reco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119995</th>\n",
       "      <td>KARACHI (Reuters) - Pakistani President Perve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119996</th>\n",
       "      <td>Red Sox general manager Theo Epstein acknowled...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119997</th>\n",
       "      <td>The Miami Dolphins will put their courtship of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119998</th>\n",
       "      <td>PITTSBURGH at NY GIANTS Time: 1:30 p.m. Line: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119999</th>\n",
       "      <td>INDIANAPOLIS -- All-Star Vince Carter was trad...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        0\n",
       "0       Reuters - Short-sellers, Wall Street's dwindli...\n",
       "1       Reuters - Private investment firm Carlyle Grou...\n",
       "2       Reuters - Soaring crude prices plus worries\\ab...\n",
       "3       Reuters - Authorities have halted oil export\\f...\n",
       "4       AFP - Tearaway world oil prices, toppling reco...\n",
       "...                                                   ...\n",
       "119995   KARACHI (Reuters) - Pakistani President Perve...\n",
       "119996  Red Sox general manager Theo Epstein acknowled...\n",
       "119997  The Miami Dolphins will put their courtship of...\n",
       "119998  PITTSBURGH at NY GIANTS Time: 1:30 p.m. Line: ...\n",
       "119999  INDIANAPOLIS -- All-Star Vince Carter was trad...\n",
       "\n",
       "[120000 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_splitted_texts = [line.split('\\n') for line in train_dataset['Description']]\n",
    "pd.DataFrame(train_dataset_splitted_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reuters - Short-sellers, Wall Street's dwindli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reuters - Private investment firm Carlyle Grou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Reuters - Soaring crude prices plus worries\\ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Reuters - Authorities have halted oil export\\f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFP - Tearaway world oil prices, toppling reco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119995</th>\n",
       "      <td>KARACHI (Reuters) - Pakistani President Perve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119996</th>\n",
       "      <td>Red Sox general manager Theo Epstein acknowled...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119997</th>\n",
       "      <td>The Miami Dolphins will put their courtship of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119998</th>\n",
       "      <td>PITTSBURGH at NY GIANTS Time: 1:30 p.m. Line: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119999</th>\n",
       "      <td>INDIANAPOLIS -- All-Star Vince Carter was trad...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        0\n",
       "0       Reuters - Short-sellers, Wall Street's dwindli...\n",
       "1       Reuters - Private investment firm Carlyle Grou...\n",
       "2       Reuters - Soaring crude prices plus worries\\ab...\n",
       "3       Reuters - Authorities have halted oil export\\f...\n",
       "4       AFP - Tearaway world oil prices, toppling reco...\n",
       "...                                                   ...\n",
       "119995   KARACHI (Reuters) - Pakistani President Perve...\n",
       "119996  Red Sox general manager Theo Epstein acknowled...\n",
       "119997  The Miami Dolphins will put their courtship of...\n",
       "119998  PITTSBURGH at NY GIANTS Time: 1:30 p.m. Line: ...\n",
       "119999  INDIANAPOLIS -- All-Star Vince Carter was trad...\n",
       "\n",
       "[120000 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_removed_stopwords = [' '.join([word if word not in stop_words.get_stop_words('en') else '' for word in text]) for text in train_dataset_splitted_texts]\n",
    "pd.DataFrame(train_removed_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reuters  Shortsellers Wall Streets dwindlingba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reuters  Private investment firm Carlyle Group...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Reuters  Soaring crude prices plus worriesabou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Reuters  Authorities have halted oil exportflo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFP  Tearaway world oil prices toppling record...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119995</th>\n",
       "      <td>KARACHI Reuters  Pakistani President Pervez M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119996</th>\n",
       "      <td>Red Sox general manager Theo Epstein acknowled...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119997</th>\n",
       "      <td>The Miami Dolphins will put their courtship of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119998</th>\n",
       "      <td>PITTSBURGH at NY GIANTS Time 130 pm Line Steel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119999</th>\n",
       "      <td>INDIANAPOLIS  AllStar Vince Carter was traded ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        0\n",
       "0       Reuters  Shortsellers Wall Streets dwindlingba...\n",
       "1       Reuters  Private investment firm Carlyle Group...\n",
       "2       Reuters  Soaring crude prices plus worriesabou...\n",
       "3       Reuters  Authorities have halted oil exportflo...\n",
       "4       AFP  Tearaway world oil prices toppling record...\n",
       "...                                                   ...\n",
       "119995   KARACHI Reuters  Pakistani President Pervez M...\n",
       "119996  Red Sox general manager Theo Epstein acknowled...\n",
       "119997  The Miami Dolphins will put their courtship of...\n",
       "119998  PITTSBURGH at NY GIANTS Time 130 pm Line Steel...\n",
       "119999  INDIANAPOLIS  AllStar Vince Carter was traded ...\n",
       "\n",
       "[120000 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_removed_punctuation = [' '.join([(' '.join(text)).translate(str.maketrans('', '', str(\"!\\\"\\'(),-./:;?\\\\`\")))]) for text in train_dataset_splitted_texts]\n",
    "pd.DataFrame(train_removed_punctuation)\n",
    "# train_removed_punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_symbols = u''.join(['№', '«', 'ђ', '°', '±', '‚', 'ћ', '‰', '…', '»', 'ѓ', 'µ', '·', 'ґ', 'њ', 'ї', 'џ', 'є', '‹',\n",
    "                            '‡', '†', '¶', 'ќ', '€', '“', 'ў', '§', '„', '”', '\\ufeff', '’', 'љ', '›', '•', '—', '‘', \n",
    "                            '\\x7f', '\\xad', '¤', '\\xa0', '\\u200b', '–']) + string.punctuation\n",
    "regex_symb = re.compile('[%s]' % re.escape(exclude_symbols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reuters Shortsellers Wall Streets dwindlingban...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reuters Private investment firm Carlyle Groupw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Reuters Soaring crude prices plus worriesabout...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Reuters Authorities have halted oil exportflow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFP Tearaway world oil prices toppling records...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119995</th>\n",
       "      <td>KARACHI Reuters Pakistani President Pervez Mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119996</th>\n",
       "      <td>Red Sox general manager Theo Epstein acknowled...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119997</th>\n",
       "      <td>The Miami Dolphins will put their courtship of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119998</th>\n",
       "      <td>PITTSBURGH at NY GIANTS Time 130 pm Line Steel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119999</th>\n",
       "      <td>INDIANAPOLIS AllStar Vince Carter was traded b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        0\n",
       "0       Reuters Shortsellers Wall Streets dwindlingban...\n",
       "1       Reuters Private investment firm Carlyle Groupw...\n",
       "2       Reuters Soaring crude prices plus worriesabout...\n",
       "3       Reuters Authorities have halted oil exportflow...\n",
       "4       AFP Tearaway world oil prices toppling records...\n",
       "...                                                   ...\n",
       "119995   KARACHI Reuters Pakistani President Pervez Mu...\n",
       "119996  Red Sox general manager Theo Epstein acknowled...\n",
       "119997  The Miami Dolphins will put their courtship of...\n",
       "119998  PITTSBURGH at NY GIANTS Time 130 pm Line Steel...\n",
       "119999  INDIANAPOLIS AllStar Vince Carter was traded b...\n",
       "\n",
       "[120000 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_removed_trash = [regex_symb.sub('', ' '.join(text)) for text in train_dataset_splitted_texts]\n",
    "train_removed_trash = [re.sub(r' +', ' ', text) for text in train_removed_trash]\n",
    "pd.DataFrame(train_removed_trash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reuters - Short-sellers, Wall Street's dwindli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reuters - Private investment firm Carlyle Grou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Reuters - Soaring crude prices plus worries\\ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Reuters - Authorities have halted oil export\\f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFP - Tearaway world oil prices, toppling reco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119995</th>\n",
       "      <td>KARACHI (Reuters) - Pakistani President Perve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119996</th>\n",
       "      <td>Red Sox general manager Theo Epstein acknowled...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119997</th>\n",
       "      <td>The Miami Dolphins will put their courtship of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119998</th>\n",
       "      <td>PITTSBURGH at NY GIANTS Time: : p.m. Line: Ste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119999</th>\n",
       "      <td>INDIANAPOLIS -- All-Star Vince Carter was trad...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        0\n",
       "0       Reuters - Short-sellers, Wall Street's dwindli...\n",
       "1       Reuters - Private investment firm Carlyle Grou...\n",
       "2       Reuters - Soaring crude prices plus worries\\ab...\n",
       "3       Reuters - Authorities have halted oil export\\f...\n",
       "4       AFP - Tearaway world oil prices, toppling reco...\n",
       "...                                                   ...\n",
       "119995   KARACHI (Reuters) - Pakistani President Perve...\n",
       "119996  Red Sox general manager Theo Epstein acknowled...\n",
       "119997  The Miami Dolphins will put their courtship of...\n",
       "119998  PITTSBURGH at NY GIANTS Time: : p.m. Line: Ste...\n",
       "119999  INDIANAPOLIS -- All-Star Vince Carter was trad...\n",
       "\n",
       "[120000 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex_digit = re.compile('[%s]' % re.escape(string.digits))\n",
    "train_removed_digits = [regex_digit.sub('', ' '.join(text)) for text in train_dataset_splitted_texts]\n",
    "pd.DataFrame(train_removed_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words=stop_words.get_stop_words('en'), max_features=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.metrics import precision_score, accuracy_score, recall_score, f1_score\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = train_dataset[\"Class Index\"]\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/.local/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aren', 'can', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'let', 'll', 'mustn', 're', 'shan', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "CVect_stopwords = vectorizer.fit_transform(train_removed_stopwords).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(CVect_stopwords, Y, test_size=0.25, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_grid_search_info(model):\n",
    "    print(f'Best estimator -> {model.best_estimator_}\\n\\\n",
    "Best Score -> {model.best_score_}\\n\\\n",
    "Best Parameters -> {model.best_params_}\\n\\\n",
    "Best index -> {model.best_index_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gridsearch_for_model(model, parameters : dict) -> GridSearchCV:\n",
    "    model_grid = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=parameters,\n",
    "        scoring=['f1_micro', 'accuracy', 'recall_macro'],\n",
    "        refit='f1_micro',\n",
    "        cv=3,\n",
    "        verbose=3,\n",
    "        error_score=0\n",
    "    )\n",
    "    return model_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(y_test, y_pred):\n",
    "    print(f'f1_micro = {f1_score(y_test, y_pred, average=\"micro\")}\\nrecall_score = {recall_score(y_test, y_pred, average=\"macro\")}\\nprecision_score = {precision_score(y_test, y_pred, average=\"macro\")}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(path:str, model):\n",
    "    with open(path, mode='wb') as pickle_file:\n",
    "        pickle.dump(model, pickle_file)\n",
    "\n",
    "def load_model(path:str):\n",
    "    with open('./models/lin_svc.pkl', mode='rb') as pickle_file:\n",
    "        model = pickle.load(pickle_file)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_logreg = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.01, 0.1, 0.5, 1.0, 10.0],\n",
    "    'solver': ['lbfgs', 'liblinear'],\n",
    "    'max_iter': [100, 500]\n",
    "}\n",
    "\n",
    "grid_log = get_gridsearch_for_model(LogisticRegression(), parameters_logreg)\n",
    "\n",
    "grid_log.fit(X_train, Y_train)\n",
    "print_grid_search_info(grid_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score = 0.9016666666666667\n",
      "recall_score = 0.9014730717851448\n",
      "precision_score = 0.9013132593705164\n"
     ]
    }
   ],
   "source": [
    "Y_pred_logreg = grid_log.predict(X_test)\n",
    "print_metrics(Y_test, Y_pred_logreg)\n",
    "save_model('./models/log_reg.pkl', grid_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_linSVC = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'loss': ['hinge', 'squared_hinge'],\n",
    "    'C': np.linspace(0.001, 0.1, 5),\n",
    "    'max_iter': [1000, 3000, 5000],\n",
    "    'dual':[True]\n",
    "}\n",
    "\n",
    "grid_linearSVC = get_gridsearch_for_model(LinearSVC(), parameters_linSVC)\n",
    "\n",
    "grid_linearSVC.fit(X_train, Y_train)\n",
    "print_grid_search_info(grid_linearSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score = 0.9051999999999999\n",
      "recall_score = 0.9050006500418074\n",
      "precision_score = 0.9049231276210165\n"
     ]
    }
   ],
   "source": [
    "Y_pred_linSVC = grid_linearSVC.predict(X_test)\n",
    "print_metrics(Y_test, Y_pred_linSVC)\n",
    "save_model('./models/lin_svc.pkl', grid_linearSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters_RFC = {\n",
    "#     'n_estimators': [10, 50, 100, 300],\n",
    "#     'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "#     'max_features': ['sqrt', 'log2'],\n",
    "# }\n",
    "\n",
    "# grid_RFC = get_gridsearch_for_model(RandomForestClassifier(), parameters_RFC)\n",
    "\n",
    "# grid_RFC.fit(X_train, Y_train)\n",
    "# print_grid_search_info(grid_RFC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_pred_RFC = grid_RFC.predict(X_test)\n",
    "# print_metrics(Y_test, Y_pred_RFC)\n",
    "# save_model('./models/RFC.pkl', grid_RFC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_KNN = {\n",
    "    'n_neighbors' : [5, 6, 7],\n",
    "    'weights' : ['uniform', 'distance'],\n",
    "    'leaf_size' : [1, 2, 3],\n",
    "    'n_jobs' : [10]\n",
    "}\n",
    "\n",
    "grid_KNN = get_gridsearch_for_model(KNeighborsClassifier(), parameters_KNN)\n",
    "\n",
    "grid_KNN.fit(X_train, Y_train)\n",
    "print_grid_search_info(grid_KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score = 0.5876333333333333\n",
      "recall_score = 0.5868685205825099\n",
      "precision_score = 0.6719880795980494\n"
     ]
    }
   ],
   "source": [
    "Y_pred_KNN = grid_KNN.predict(X_test)\n",
    "print_metrics(Y_test, Y_pred_KNN)\n",
    "save_model('./models/KNN.pkl', grid_RFC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters_MNB = {\n",
    "#     'alpha' : np.linspace(0.3, 0.4, 100)\n",
    "# }\n",
    "\n",
    "# grid_MNB = get_gridsearch_for_model(MultinomialNB(),parameters_MNB)\n",
    "\n",
    "# grid_MNB.fit(X_train, Y_train)\n",
    "# print_grid_search_info(grid_MNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_pred_MNB = grid_MNB.predict(X_test)\n",
    "# print_metrics(Y_test, Y_pred_MNB)\n",
    "# save_model('./models/MNB.pkl', grid_RFC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/.local/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aren', 'can', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'let', 'll', 'mustn', 're', 'shan', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "CVect_trash = vectorizer.fit_transform(train_removed_trash).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(CVect_trash, Y, test_size=0.25, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n",
      "[CV 1/3] END C=0.01, max_iter=100, penalty=l1, solver=lbfgs; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.4s\n",
      "[CV 2/3] END C=0.01, max_iter=100, penalty=l1, solver=lbfgs; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   1.9s\n",
      "[CV 3/3] END C=0.01, max_iter=100, penalty=l1, solver=lbfgs; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.3s\n",
      "[CV 1/3] END C=0.01, max_iter=100, penalty=l1, solver=liblinear; accuracy: (test=0.784) f1_micro: (test=0.784) recall_macro: (test=0.784) total time=   8.7s\n",
      "[CV 2/3] END C=0.01, max_iter=100, penalty=l1, solver=liblinear; accuracy: (test=0.782) f1_micro: (test=0.782) recall_macro: (test=0.782) total time=   6.5s\n",
      "[CV 3/3] END C=0.01, max_iter=100, penalty=l1, solver=liblinear; accuracy: (test=0.783) f1_micro: (test=0.783) recall_macro: (test=0.783) total time=  10.9s\n",
      "[CV 1/3] END C=0.01, max_iter=100, penalty=l2, solver=lbfgs; accuracy: (test=0.879) f1_micro: (test=0.879) recall_macro: (test=0.879) total time= 1.0min\n",
      "[CV 2/3] END C=0.01, max_iter=100, penalty=l2, solver=lbfgs; accuracy: (test=0.878) f1_micro: (test=0.878) recall_macro: (test=0.878) total time=  45.4s\n",
      "[CV 3/3] END C=0.01, max_iter=100, penalty=l2, solver=lbfgs; accuracy: (test=0.879) f1_micro: (test=0.879) recall_macro: (test=0.879) total time=  47.7s\n",
      "[CV 1/3] END C=0.01, max_iter=100, penalty=l2, solver=liblinear; accuracy: (test=0.874) f1_micro: (test=0.874) recall_macro: (test=0.874) total time=   6.6s\n",
      "[CV 2/3] END C=0.01, max_iter=100, penalty=l2, solver=liblinear; accuracy: (test=0.873) f1_micro: (test=0.873) recall_macro: (test=0.874) total time=   7.1s\n",
      "[CV 3/3] END C=0.01, max_iter=100, penalty=l2, solver=liblinear; accuracy: (test=0.874) f1_micro: (test=0.874) recall_macro: (test=0.874) total time=   6.2s\n",
      "[CV 1/3] END C=0.01, max_iter=500, penalty=l1, solver=lbfgs; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   1.1s\n",
      "[CV 2/3] END C=0.01, max_iter=500, penalty=l1, solver=lbfgs; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   1.3s\n",
      "[CV 3/3] END C=0.01, max_iter=500, penalty=l1, solver=lbfgs; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   1.1s\n",
      "[CV 1/3] END C=0.01, max_iter=500, penalty=l1, solver=liblinear; accuracy: (test=0.784) f1_micro: (test=0.784) recall_macro: (test=0.784) total time=   4.8s\n",
      "[CV 2/3] END C=0.01, max_iter=500, penalty=l1, solver=liblinear; accuracy: (test=0.782) f1_micro: (test=0.782) recall_macro: (test=0.782) total time=   4.7s\n",
      "[CV 3/3] END C=0.01, max_iter=500, penalty=l1, solver=liblinear; accuracy: (test=0.783) f1_micro: (test=0.783) recall_macro: (test=0.783) total time=   5.2s\n",
      "[CV 1/3] END C=0.01, max_iter=500, penalty=l2, solver=lbfgs; accuracy: (test=0.879) f1_micro: (test=0.879) recall_macro: (test=0.879) total time=  44.0s\n",
      "[CV 2/3] END C=0.01, max_iter=500, penalty=l2, solver=lbfgs; accuracy: (test=0.878) f1_micro: (test=0.878) recall_macro: (test=0.878) total time=  43.3s\n",
      "[CV 3/3] END C=0.01, max_iter=500, penalty=l2, solver=lbfgs; accuracy: (test=0.879) f1_micro: (test=0.879) recall_macro: (test=0.879) total time=  46.8s\n",
      "[CV 1/3] END C=0.01, max_iter=500, penalty=l2, solver=liblinear; accuracy: (test=0.874) f1_micro: (test=0.874) recall_macro: (test=0.874) total time=   6.0s\n",
      "[CV 2/3] END C=0.01, max_iter=500, penalty=l2, solver=liblinear; accuracy: (test=0.873) f1_micro: (test=0.873) recall_macro: (test=0.874) total time=   6.1s\n",
      "[CV 3/3] END C=0.01, max_iter=500, penalty=l2, solver=liblinear; accuracy: (test=0.874) f1_micro: (test=0.874) recall_macro: (test=0.874) total time=   7.0s\n",
      "[CV 1/3] END C=0.1, max_iter=100, penalty=l1, solver=lbfgs; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   1.1s\n",
      "[CV 2/3] END C=0.1, max_iter=100, penalty=l1, solver=lbfgs; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   1.3s\n",
      "[CV 3/3] END C=0.1, max_iter=100, penalty=l1, solver=lbfgs; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   1.1s\n",
      "[CV 1/3] END C=0.1, max_iter=100, penalty=l1, solver=liblinear; accuracy: (test=0.873) f1_micro: (test=0.873) recall_macro: (test=0.873) total time=   5.2s\n",
      "[CV 2/3] END C=0.1, max_iter=100, penalty=l1, solver=liblinear; accuracy: (test=0.871) f1_micro: (test=0.871) recall_macro: (test=0.871) total time=   4.9s\n",
      "[CV 3/3] END C=0.1, max_iter=100, penalty=l1, solver=liblinear; accuracy: (test=0.873) f1_micro: (test=0.873) recall_macro: (test=0.873) total time=   5.3s\n",
      "[CV 1/3] END C=0.1, max_iter=100, penalty=l2, solver=lbfgs; accuracy: (test=0.894) f1_micro: (test=0.894) recall_macro: (test=0.894) total time= 2.4min\n",
      "[CV 2/3] END C=0.1, max_iter=100, penalty=l2, solver=lbfgs; accuracy: (test=0.894) f1_micro: (test=0.894) recall_macro: (test=0.894) total time= 2.2min\n",
      "[CV 3/3] END C=0.1, max_iter=100, penalty=l2, solver=lbfgs; accuracy: (test=0.896) f1_micro: (test=0.896) recall_macro: (test=0.896) total time= 2.4min\n",
      "[CV 1/3] END C=0.1, max_iter=100, penalty=l2, solver=liblinear; accuracy: (test=0.895) f1_micro: (test=0.895) recall_macro: (test=0.895) total time=  11.1s\n",
      "[CV 2/3] END C=0.1, max_iter=100, penalty=l2, solver=liblinear; accuracy: (test=0.896) f1_micro: (test=0.896) recall_macro: (test=0.896) total time=   9.2s\n",
      "[CV 3/3] END C=0.1, max_iter=100, penalty=l2, solver=liblinear; accuracy: (test=0.896) f1_micro: (test=0.896) recall_macro: (test=0.897) total time=   9.4s\n",
      "[CV 1/3] END C=0.1, max_iter=500, penalty=l1, solver=lbfgs; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   1.1s\n",
      "[CV 2/3] END C=0.1, max_iter=500, penalty=l1, solver=lbfgs; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   1.1s\n",
      "[CV 3/3] END C=0.1, max_iter=500, penalty=l1, solver=lbfgs; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   1.1s\n",
      "[CV 1/3] END C=0.1, max_iter=500, penalty=l1, solver=liblinear; accuracy: (test=0.873) f1_micro: (test=0.873) recall_macro: (test=0.873) total time=   5.2s\n",
      "[CV 2/3] END C=0.1, max_iter=500, penalty=l1, solver=liblinear; accuracy: (test=0.871) f1_micro: (test=0.871) recall_macro: (test=0.871) total time=   5.2s\n",
      "[CV 3/3] END C=0.1, max_iter=500, penalty=l1, solver=liblinear; accuracy: (test=0.873) f1_micro: (test=0.873) recall_macro: (test=0.873) total time=   4.8s\n",
      "[CV 1/3] END C=0.1, max_iter=500, penalty=l2, solver=lbfgs; accuracy: (test=0.894) f1_micro: (test=0.894) recall_macro: (test=0.894) total time= 2.3min\n",
      "[CV 2/3] END C=0.1, max_iter=500, penalty=l2, solver=lbfgs; accuracy: (test=0.894) f1_micro: (test=0.894) recall_macro: (test=0.894) total time= 2.2min\n",
      "[CV 3/3] END C=0.1, max_iter=500, penalty=l2, solver=lbfgs; accuracy: (test=0.896) f1_micro: (test=0.896) recall_macro: (test=0.896) total time= 2.2min\n",
      "[CV 1/3] END C=0.1, max_iter=500, penalty=l2, solver=liblinear; accuracy: (test=0.895) f1_micro: (test=0.895) recall_macro: (test=0.895) total time=   9.5s\n",
      "[CV 2/3] END C=0.1, max_iter=500, penalty=l2, solver=liblinear; accuracy: (test=0.896) f1_micro: (test=0.896) recall_macro: (test=0.896) total time=   8.8s\n",
      "[CV 3/3] END C=0.1, max_iter=500, penalty=l2, solver=liblinear; accuracy: (test=0.896) f1_micro: (test=0.896) recall_macro: (test=0.897) total time=   9.5s\n",
      "[CV 1/3] END C=0.5, max_iter=100, penalty=l1, solver=lbfgs; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   1.0s\n",
      "[CV 2/3] END C=0.5, max_iter=100, penalty=l1, solver=lbfgs; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   1.2s\n",
      "[CV 3/3] END C=0.5, max_iter=100, penalty=l1, solver=lbfgs; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   1.1s\n",
      "[CV 1/3] END C=0.5, max_iter=100, penalty=l1, solver=liblinear; accuracy: (test=0.894) f1_micro: (test=0.894) recall_macro: (test=0.894) total time=   5.6s\n",
      "[CV 2/3] END C=0.5, max_iter=100, penalty=l1, solver=liblinear; accuracy: (test=0.896) f1_micro: (test=0.896) recall_macro: (test=0.896) total time=   5.1s\n",
      "[CV 3/3] END C=0.5, max_iter=100, penalty=l1, solver=liblinear; accuracy: (test=0.895) f1_micro: (test=0.895) recall_macro: (test=0.895) total time=   5.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.5, max_iter=100, penalty=l2, solver=lbfgs; accuracy: (test=0.889) f1_micro: (test=0.889) recall_macro: (test=0.889) total time= 2.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=0.5, max_iter=100, penalty=l2, solver=lbfgs; accuracy: (test=0.890) f1_micro: (test=0.890) recall_macro: (test=0.890) total time= 2.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.5, max_iter=100, penalty=l2, solver=lbfgs; accuracy: (test=0.890) f1_micro: (test=0.890) recall_macro: (test=0.890) total time= 2.4min\n",
      "[CV 1/3] END C=0.5, max_iter=100, penalty=l2, solver=liblinear; accuracy: (test=0.896) f1_micro: (test=0.896) recall_macro: (test=0.896) total time=  11.6s\n",
      "[CV 2/3] END C=0.5, max_iter=100, penalty=l2, solver=liblinear; accuracy: (test=0.897) f1_micro: (test=0.897) recall_macro: (test=0.898) total time=  10.6s\n",
      "[CV 3/3] END C=0.5, max_iter=100, penalty=l2, solver=liblinear; accuracy: (test=0.898) f1_micro: (test=0.898) recall_macro: (test=0.898) total time=  10.5s\n",
      "[CV 1/3] END C=0.5, max_iter=500, penalty=l1, solver=lbfgs; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   1.1s\n",
      "[CV 2/3] END C=0.5, max_iter=500, penalty=l1, solver=lbfgs; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   1.2s\n",
      "[CV 3/3] END C=0.5, max_iter=500, penalty=l1, solver=lbfgs; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   1.1s\n",
      "[CV 1/3] END C=0.5, max_iter=500, penalty=l1, solver=liblinear; accuracy: (test=0.894) f1_micro: (test=0.894) recall_macro: (test=0.894) total time=   5.8s\n",
      "[CV 2/3] END C=0.5, max_iter=500, penalty=l1, solver=liblinear; accuracy: (test=0.896) f1_micro: (test=0.896) recall_macro: (test=0.896) total time=   5.1s\n",
      "[CV 3/3] END C=0.5, max_iter=500, penalty=l1, solver=liblinear; accuracy: (test=0.895) f1_micro: (test=0.895) recall_macro: (test=0.895) total time=   5.3s\n",
      "[CV 1/3] END C=0.5, max_iter=500, penalty=l2, solver=lbfgs; accuracy: (test=0.889) f1_micro: (test=0.889) recall_macro: (test=0.889) total time= 3.9min\n",
      "[CV 2/3] END C=0.5, max_iter=500, penalty=l2, solver=lbfgs; accuracy: (test=0.890) f1_micro: (test=0.890) recall_macro: (test=0.891) total time= 4.2min\n",
      "[CV 3/3] END C=0.5, max_iter=500, penalty=l2, solver=lbfgs; accuracy: (test=0.890) f1_micro: (test=0.890) recall_macro: (test=0.890) total time= 4.0min\n",
      "[CV 1/3] END C=0.5, max_iter=500, penalty=l2, solver=liblinear; accuracy: (test=0.896) f1_micro: (test=0.896) recall_macro: (test=0.896) total time=  12.4s\n",
      "[CV 2/3] END C=0.5, max_iter=500, penalty=l2, solver=liblinear; accuracy: (test=0.897) f1_micro: (test=0.897) recall_macro: (test=0.898) total time=  11.1s\n",
      "[CV 3/3] END C=0.5, max_iter=500, penalty=l2, solver=liblinear; accuracy: (test=0.898) f1_micro: (test=0.898) recall_macro: (test=0.898) total time=  10.9s\n",
      "[CV 1/3] END C=1.0, max_iter=100, penalty=l1, solver=lbfgs; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   1.0s\n",
      "[CV 2/3] END C=1.0, max_iter=100, penalty=l1, solver=lbfgs; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   1.1s\n",
      "[CV 3/3] END C=1.0, max_iter=100, penalty=l1, solver=lbfgs; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   1.1s\n",
      "[CV 1/3] END C=1.0, max_iter=100, penalty=l1, solver=liblinear; accuracy: (test=0.893) f1_micro: (test=0.893) recall_macro: (test=0.893) total time=   5.9s\n",
      "[CV 2/3] END C=1.0, max_iter=100, penalty=l1, solver=liblinear; accuracy: (test=0.894) f1_micro: (test=0.894) recall_macro: (test=0.894) total time=   5.3s\n",
      "[CV 3/3] END C=1.0, max_iter=100, penalty=l1, solver=liblinear; accuracy: (test=0.893) f1_micro: (test=0.893) recall_macro: (test=0.893) total time=   5.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=1.0, max_iter=100, penalty=l2, solver=lbfgs; accuracy: (test=0.884) f1_micro: (test=0.884) recall_macro: (test=0.884) total time= 2.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=1.0, max_iter=100, penalty=l2, solver=lbfgs; accuracy: (test=0.884) f1_micro: (test=0.884) recall_macro: (test=0.885) total time= 2.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=1.0, max_iter=100, penalty=l2, solver=lbfgs; accuracy: (test=0.884) f1_micro: (test=0.884) recall_macro: (test=0.884) total time= 2.3min\n",
      "[CV 1/3] END C=1.0, max_iter=100, penalty=l2, solver=liblinear; accuracy: (test=0.893) f1_micro: (test=0.893) recall_macro: (test=0.893) total time=  14.5s\n",
      "[CV 2/3] END C=1.0, max_iter=100, penalty=l2, solver=liblinear; accuracy: (test=0.895) f1_micro: (test=0.895) recall_macro: (test=0.895) total time=  14.1s\n",
      "[CV 3/3] END C=1.0, max_iter=100, penalty=l2, solver=liblinear; accuracy: (test=0.895) f1_micro: (test=0.895) recall_macro: (test=0.895) total time=  14.4s\n",
      "[CV 1/3] END C=1.0, max_iter=500, penalty=l1, solver=lbfgs; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   1.2s\n",
      "[CV 2/3] END C=1.0, max_iter=500, penalty=l1, solver=lbfgs; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   1.2s\n",
      "[CV 3/3] END C=1.0, max_iter=500, penalty=l1, solver=lbfgs; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   1.2s\n",
      "[CV 1/3] END C=1.0, max_iter=500, penalty=l1, solver=liblinear; accuracy: (test=0.893) f1_micro: (test=0.893) recall_macro: (test=0.893) total time=   7.4s\n",
      "[CV 2/3] END C=1.0, max_iter=500, penalty=l1, solver=liblinear; accuracy: (test=0.894) f1_micro: (test=0.894) recall_macro: (test=0.894) total time=   5.7s\n",
      "[CV 3/3] END C=1.0, max_iter=500, penalty=l1, solver=liblinear; accuracy: (test=0.893) f1_micro: (test=0.893) recall_macro: (test=0.893) total time=   5.4s\n",
      "[CV 1/3] END C=1.0, max_iter=500, penalty=l2, solver=lbfgs; accuracy: (test=0.884) f1_micro: (test=0.884) recall_macro: (test=0.884) total time= 5.1min\n",
      "[CV 2/3] END C=1.0, max_iter=500, penalty=l2, solver=lbfgs; accuracy: (test=0.884) f1_micro: (test=0.884) recall_macro: (test=0.884) total time= 5.2min\n",
      "[CV 3/3] END C=1.0, max_iter=500, penalty=l2, solver=lbfgs; accuracy: (test=0.884) f1_micro: (test=0.884) recall_macro: (test=0.884) total time= 5.0min\n",
      "[CV 1/3] END C=1.0, max_iter=500, penalty=l2, solver=liblinear; accuracy: (test=0.893) f1_micro: (test=0.893) recall_macro: (test=0.893) total time=  15.0s\n",
      "[CV 2/3] END C=1.0, max_iter=500, penalty=l2, solver=liblinear; accuracy: (test=0.895) f1_micro: (test=0.895) recall_macro: (test=0.895) total time=  14.6s\n",
      "[CV 3/3] END C=1.0, max_iter=500, penalty=l2, solver=liblinear; accuracy: (test=0.895) f1_micro: (test=0.895) recall_macro: (test=0.895) total time=  16.6s\n",
      "[CV 1/3] END C=10.0, max_iter=100, penalty=l1, solver=lbfgs; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.3s\n",
      "[CV 2/3] END C=10.0, max_iter=100, penalty=l1, solver=lbfgs; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   1.2s\n",
      "[CV 3/3] END C=10.0, max_iter=100, penalty=l1, solver=lbfgs; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   1.2s\n",
      "[CV 1/3] END C=10.0, max_iter=100, penalty=l1, solver=liblinear; accuracy: (test=0.862) f1_micro: (test=0.862) recall_macro: (test=0.862) total time=   6.5s\n",
      "[CV 2/3] END C=10.0, max_iter=100, penalty=l1, solver=liblinear; accuracy: (test=0.861) f1_micro: (test=0.861) recall_macro: (test=0.861) total time=   6.0s\n",
      "[CV 3/3] END C=10.0, max_iter=100, penalty=l1, solver=liblinear; accuracy: (test=0.860) f1_micro: (test=0.860) recall_macro: (test=0.860) total time=   5.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=10.0, max_iter=100, penalty=l2, solver=lbfgs; accuracy: (test=0.862) f1_micro: (test=0.862) recall_macro: (test=0.862) total time= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=10.0, max_iter=100, penalty=l2, solver=lbfgs; accuracy: (test=0.862) f1_micro: (test=0.862) recall_macro: (test=0.862) total time= 1.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=10.0, max_iter=100, penalty=l2, solver=lbfgs; accuracy: (test=0.863) f1_micro: (test=0.863) recall_macro: (test=0.863) total time= 1.5min\n",
      "[CV 1/3] END C=10.0, max_iter=100, penalty=l2, solver=liblinear; accuracy: (test=0.874) f1_micro: (test=0.874) recall_macro: (test=0.874) total time=  18.2s\n",
      "[CV 2/3] END C=10.0, max_iter=100, penalty=l2, solver=liblinear; accuracy: (test=0.873) f1_micro: (test=0.873) recall_macro: (test=0.873) total time=  16.3s\n",
      "[CV 3/3] END C=10.0, max_iter=100, penalty=l2, solver=liblinear; accuracy: (test=0.874) f1_micro: (test=0.874) recall_macro: (test=0.874) total time=  16.3s\n",
      "[CV 1/3] END C=10.0, max_iter=500, penalty=l1, solver=lbfgs; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   1.0s\n",
      "[CV 2/3] END C=10.0, max_iter=500, penalty=l1, solver=lbfgs; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   1.1s\n",
      "[CV 3/3] END C=10.0, max_iter=500, penalty=l1, solver=lbfgs; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   1.1s\n",
      "[CV 1/3] END C=10.0, max_iter=500, penalty=l1, solver=liblinear; accuracy: (test=0.862) f1_micro: (test=0.862) recall_macro: (test=0.862) total time=   6.2s\n",
      "[CV 2/3] END C=10.0, max_iter=500, penalty=l1, solver=liblinear; accuracy: (test=0.861) f1_micro: (test=0.861) recall_macro: (test=0.861) total time=   6.3s\n",
      "[CV 3/3] END C=10.0, max_iter=500, penalty=l1, solver=liblinear; accuracy: (test=0.860) f1_micro: (test=0.860) recall_macro: (test=0.860) total time=   6.0s\n",
      "[CV 1/3] END C=10.0, max_iter=500, penalty=l2, solver=lbfgs; accuracy: (test=0.858) f1_micro: (test=0.858) recall_macro: (test=0.858) total time= 6.4min\n",
      "[CV 2/3] END C=10.0, max_iter=500, penalty=l2, solver=lbfgs; accuracy: (test=0.857) f1_micro: (test=0.857) recall_macro: (test=0.857) total time= 6.5min\n",
      "[CV 3/3] END C=10.0, max_iter=500, penalty=l2, solver=lbfgs; accuracy: (test=0.857) f1_micro: (test=0.857) recall_macro: (test=0.857) total time=11.3min\n",
      "[CV 1/3] END C=10.0, max_iter=500, penalty=l2, solver=liblinear; accuracy: (test=0.874) f1_micro: (test=0.874) recall_macro: (test=0.874) total time=  20.8s\n",
      "[CV 2/3] END C=10.0, max_iter=500, penalty=l2, solver=liblinear; accuracy: (test=0.873) f1_micro: (test=0.873) recall_macro: (test=0.873) total time=  17.3s\n",
      "[CV 3/3] END C=10.0, max_iter=500, penalty=l2, solver=liblinear; accuracy: (test=0.874) f1_micro: (test=0.874) recall_macro: (test=0.874) total time=  17.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "30 fits failed out of a total of 120.\n",
      "The score on these train-test partitions for these parameters will be set to 0.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/habkaffee/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/habkaffee/.local/lib/python3.10/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/home/habkaffee/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/habkaffee/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator -> LogisticRegression(C=0.5, solver='liblinear')\n",
      "Best Score -> 0.8971777777777779\n",
      "Best Parameters -> {'C': 0.5, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Best index -> 19\n"
     ]
    }
   ],
   "source": [
    "parameters_logreg = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.01, 0.1, 0.5, 1.0, 10.0],\n",
    "    'solver': ['lbfgs', 'liblinear'],\n",
    "    'max_iter': [100, 500]\n",
    "}\n",
    "\n",
    "grid_log = get_gridsearch_for_model(LogisticRegression(), parameters_logreg)\n",
    "\n",
    "grid_log.fit(X_train, Y_train)\n",
    "print_grid_search_info(grid_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score = 0.8989\n",
      "recall_score = 0.8987174214816545\n",
      "precision_score = 0.8985895429774059\n"
     ]
    }
   ],
   "source": [
    "Y_pred_logreg = grid_log.predict(X_test)\n",
    "print_metrics(Y_test, Y_pred_logreg)\n",
    "save_model('./models/log_reg_trash.pkl', grid_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 60 candidates, totalling 180 fits\n",
      "[CV 1/3] END C=0.001, dual=True, loss=hinge, max_iter=1000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   3.8s\n",
      "[CV 2/3] END C=0.001, dual=True, loss=hinge, max_iter=1000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   3.7s\n",
      "[CV 3/3] END C=0.001, dual=True, loss=hinge, max_iter=1000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.7s\n",
      "[CV 1/3] END C=0.001, dual=True, loss=hinge, max_iter=1000, penalty=l2; accuracy: (test=0.860) f1_micro: (test=0.860) recall_macro: (test=0.860) total time=   4.6s\n",
      "[CV 2/3] END C=0.001, dual=True, loss=hinge, max_iter=1000, penalty=l2; accuracy: (test=0.859) f1_micro: (test=0.859) recall_macro: (test=0.859) total time=   5.3s\n",
      "[CV 3/3] END C=0.001, dual=True, loss=hinge, max_iter=1000, penalty=l2; accuracy: (test=0.861) f1_micro: (test=0.861) recall_macro: (test=0.861) total time=   4.5s\n",
      "[CV 1/3] END C=0.001, dual=True, loss=hinge, max_iter=3000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.2s\n",
      "[CV 2/3] END C=0.001, dual=True, loss=hinge, max_iter=3000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.0s\n",
      "[CV 3/3] END C=0.001, dual=True, loss=hinge, max_iter=3000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   1.9s\n",
      "[CV 1/3] END C=0.001, dual=True, loss=hinge, max_iter=3000, penalty=l2; accuracy: (test=0.860) f1_micro: (test=0.860) recall_macro: (test=0.860) total time=   4.6s\n",
      "[CV 2/3] END C=0.001, dual=True, loss=hinge, max_iter=3000, penalty=l2; accuracy: (test=0.859) f1_micro: (test=0.859) recall_macro: (test=0.859) total time=   4.9s\n",
      "[CV 3/3] END C=0.001, dual=True, loss=hinge, max_iter=3000, penalty=l2; accuracy: (test=0.861) f1_micro: (test=0.861) recall_macro: (test=0.861) total time=   4.6s\n",
      "[CV 1/3] END C=0.001, dual=True, loss=hinge, max_iter=5000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.2s\n",
      "[CV 2/3] END C=0.001, dual=True, loss=hinge, max_iter=5000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.1s\n",
      "[CV 3/3] END C=0.001, dual=True, loss=hinge, max_iter=5000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   1.9s\n",
      "[CV 1/3] END C=0.001, dual=True, loss=hinge, max_iter=5000, penalty=l2; accuracy: (test=0.860) f1_micro: (test=0.860) recall_macro: (test=0.860) total time=   5.1s\n",
      "[CV 2/3] END C=0.001, dual=True, loss=hinge, max_iter=5000, penalty=l2; accuracy: (test=0.859) f1_micro: (test=0.859) recall_macro: (test=0.859) total time=   4.6s\n",
      "[CV 3/3] END C=0.001, dual=True, loss=hinge, max_iter=5000, penalty=l2; accuracy: (test=0.861) f1_micro: (test=0.861) recall_macro: (test=0.861) total time=   4.4s\n",
      "[CV 1/3] END C=0.001, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.1s\n",
      "[CV 2/3] END C=0.001, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.1s\n",
      "[CV 3/3] END C=0.001, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.1s\n",
      "[CV 1/3] END C=0.001, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; accuracy: (test=0.878) f1_micro: (test=0.878) recall_macro: (test=0.878) total time=   4.4s\n",
      "[CV 2/3] END C=0.001, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; accuracy: (test=0.878) f1_micro: (test=0.878) recall_macro: (test=0.878) total time=   4.7s\n",
      "[CV 3/3] END C=0.001, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; accuracy: (test=0.879) f1_micro: (test=0.879) recall_macro: (test=0.879) total time=   4.7s\n",
      "[CV 1/3] END C=0.001, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.0s\n",
      "[CV 2/3] END C=0.001, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   1.9s\n",
      "[CV 3/3] END C=0.001, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.3s\n",
      "[CV 1/3] END C=0.001, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; accuracy: (test=0.878) f1_micro: (test=0.878) recall_macro: (test=0.878) total time=   5.4s\n",
      "[CV 2/3] END C=0.001, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; accuracy: (test=0.878) f1_micro: (test=0.878) recall_macro: (test=0.878) total time=   5.1s\n",
      "[CV 3/3] END C=0.001, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; accuracy: (test=0.879) f1_micro: (test=0.879) recall_macro: (test=0.879) total time=   4.9s\n",
      "[CV 1/3] END C=0.001, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.1s\n",
      "[CV 2/3] END C=0.001, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.1s\n",
      "[CV 3/3] END C=0.001, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   1.9s\n",
      "[CV 1/3] END C=0.001, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; accuracy: (test=0.878) f1_micro: (test=0.878) recall_macro: (test=0.878) total time=   4.8s\n",
      "[CV 2/3] END C=0.001, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; accuracy: (test=0.878) f1_micro: (test=0.878) recall_macro: (test=0.878) total time=   4.8s\n",
      "[CV 3/3] END C=0.001, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; accuracy: (test=0.879) f1_micro: (test=0.879) recall_macro: (test=0.879) total time=   4.7s\n",
      "[CV 1/3] END C=0.025750000000000002, dual=True, loss=hinge, max_iter=1000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.2s\n",
      "[CV 2/3] END C=0.025750000000000002, dual=True, loss=hinge, max_iter=1000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.1s\n",
      "[CV 3/3] END C=0.025750000000000002, dual=True, loss=hinge, max_iter=1000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.0s\n",
      "[CV 1/3] END C=0.025750000000000002, dual=True, loss=hinge, max_iter=1000, penalty=l2; accuracy: (test=0.898) f1_micro: (test=0.898) recall_macro: (test=0.898) total time=   5.1s\n",
      "[CV 2/3] END C=0.025750000000000002, dual=True, loss=hinge, max_iter=1000, penalty=l2; accuracy: (test=0.898) f1_micro: (test=0.898) recall_macro: (test=0.898) total time=   4.8s\n",
      "[CV 3/3] END C=0.025750000000000002, dual=True, loss=hinge, max_iter=1000, penalty=l2; accuracy: (test=0.900) f1_micro: (test=0.900) recall_macro: (test=0.900) total time=   4.7s\n",
      "[CV 1/3] END C=0.025750000000000002, dual=True, loss=hinge, max_iter=3000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.2s\n",
      "[CV 2/3] END C=0.025750000000000002, dual=True, loss=hinge, max_iter=3000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.0s\n",
      "[CV 3/3] END C=0.025750000000000002, dual=True, loss=hinge, max_iter=3000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.0s\n",
      "[CV 1/3] END C=0.025750000000000002, dual=True, loss=hinge, max_iter=3000, penalty=l2; accuracy: (test=0.898) f1_micro: (test=0.898) recall_macro: (test=0.898) total time=   4.8s\n",
      "[CV 2/3] END C=0.025750000000000002, dual=True, loss=hinge, max_iter=3000, penalty=l2; accuracy: (test=0.898) f1_micro: (test=0.898) recall_macro: (test=0.898) total time=   4.7s\n",
      "[CV 3/3] END C=0.025750000000000002, dual=True, loss=hinge, max_iter=3000, penalty=l2; accuracy: (test=0.900) f1_micro: (test=0.900) recall_macro: (test=0.900) total time=   4.9s\n",
      "[CV 1/3] END C=0.025750000000000002, dual=True, loss=hinge, max_iter=5000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.1s\n",
      "[CV 2/3] END C=0.025750000000000002, dual=True, loss=hinge, max_iter=5000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.0s\n",
      "[CV 3/3] END C=0.025750000000000002, dual=True, loss=hinge, max_iter=5000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.4s\n",
      "[CV 1/3] END C=0.025750000000000002, dual=True, loss=hinge, max_iter=5000, penalty=l2; accuracy: (test=0.898) f1_micro: (test=0.898) recall_macro: (test=0.898) total time=   4.9s\n",
      "[CV 2/3] END C=0.025750000000000002, dual=True, loss=hinge, max_iter=5000, penalty=l2; accuracy: (test=0.898) f1_micro: (test=0.898) recall_macro: (test=0.898) total time=   4.8s\n",
      "[CV 3/3] END C=0.025750000000000002, dual=True, loss=hinge, max_iter=5000, penalty=l2; accuracy: (test=0.900) f1_micro: (test=0.900) recall_macro: (test=0.900) total time=   4.7s\n",
      "[CV 1/3] END C=0.025750000000000002, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.1s\n",
      "[CV 2/3] END C=0.025750000000000002, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.1s\n",
      "[CV 3/3] END C=0.025750000000000002, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.0s\n",
      "[CV 1/3] END C=0.025750000000000002, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; accuracy: (test=0.898) f1_micro: (test=0.898) recall_macro: (test=0.898) total time=   5.2s\n",
      "[CV 2/3] END C=0.025750000000000002, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; accuracy: (test=0.900) f1_micro: (test=0.900) recall_macro: (test=0.900) total time=   4.7s\n",
      "[CV 3/3] END C=0.025750000000000002, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; accuracy: (test=0.900) f1_micro: (test=0.900) recall_macro: (test=0.900) total time=   4.9s\n",
      "[CV 1/3] END C=0.025750000000000002, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.2s\n",
      "[CV 2/3] END C=0.025750000000000002, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.1s\n",
      "[CV 3/3] END C=0.025750000000000002, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.0s\n",
      "[CV 1/3] END C=0.025750000000000002, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; accuracy: (test=0.898) f1_micro: (test=0.898) recall_macro: (test=0.898) total time=   4.9s\n",
      "[CV 2/3] END C=0.025750000000000002, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; accuracy: (test=0.900) f1_micro: (test=0.900) recall_macro: (test=0.900) total time=   4.8s\n",
      "[CV 3/3] END C=0.025750000000000002, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; accuracy: (test=0.900) f1_micro: (test=0.900) recall_macro: (test=0.900) total time=   5.1s\n",
      "[CV 1/3] END C=0.025750000000000002, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.1s\n",
      "[CV 2/3] END C=0.025750000000000002, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.0s\n",
      "[CV 3/3] END C=0.025750000000000002, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.0s\n",
      "[CV 1/3] END C=0.025750000000000002, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; accuracy: (test=0.898) f1_micro: (test=0.898) recall_macro: (test=0.898) total time=   5.0s\n",
      "[CV 2/3] END C=0.025750000000000002, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; accuracy: (test=0.900) f1_micro: (test=0.900) recall_macro: (test=0.900) total time=   4.8s\n",
      "[CV 3/3] END C=0.025750000000000002, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; accuracy: (test=0.900) f1_micro: (test=0.900) recall_macro: (test=0.900) total time=   4.9s\n",
      "[CV 1/3] END C=0.0505, dual=True, loss=hinge, max_iter=1000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.2s\n",
      "[CV 2/3] END C=0.0505, dual=True, loss=hinge, max_iter=1000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.1s\n",
      "[CV 3/3] END C=0.0505, dual=True, loss=hinge, max_iter=1000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.0505, dual=True, loss=hinge, max_iter=1000, penalty=l2; accuracy: (test=0.900) f1_micro: (test=0.900) recall_macro: (test=0.900) total time=   4.9s\n",
      "[CV 2/3] END C=0.0505, dual=True, loss=hinge, max_iter=1000, penalty=l2; accuracy: (test=0.900) f1_micro: (test=0.900) recall_macro: (test=0.900) total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.0505, dual=True, loss=hinge, max_iter=1000, penalty=l2; accuracy: (test=0.901) f1_micro: (test=0.901) recall_macro: (test=0.901) total time=   5.0s\n",
      "[CV 1/3] END C=0.0505, dual=True, loss=hinge, max_iter=3000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.0s\n",
      "[CV 2/3] END C=0.0505, dual=True, loss=hinge, max_iter=3000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   1.9s\n",
      "[CV 3/3] END C=0.0505, dual=True, loss=hinge, max_iter=3000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.3s\n",
      "[CV 1/3] END C=0.0505, dual=True, loss=hinge, max_iter=3000, penalty=l2; accuracy: (test=0.900) f1_micro: (test=0.900) recall_macro: (test=0.900) total time=   5.4s\n",
      "[CV 2/3] END C=0.0505, dual=True, loss=hinge, max_iter=3000, penalty=l2; accuracy: (test=0.900) f1_micro: (test=0.900) recall_macro: (test=0.900) total time=   5.9s\n",
      "[CV 3/3] END C=0.0505, dual=True, loss=hinge, max_iter=3000, penalty=l2; accuracy: (test=0.901) f1_micro: (test=0.901) recall_macro: (test=0.901) total time=   5.6s\n",
      "[CV 1/3] END C=0.0505, dual=True, loss=hinge, max_iter=5000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.3s\n",
      "[CV 2/3] END C=0.0505, dual=True, loss=hinge, max_iter=5000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.1s\n",
      "[CV 3/3] END C=0.0505, dual=True, loss=hinge, max_iter=5000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.1s\n",
      "[CV 1/3] END C=0.0505, dual=True, loss=hinge, max_iter=5000, penalty=l2; accuracy: (test=0.900) f1_micro: (test=0.900) recall_macro: (test=0.900) total time=   5.0s\n",
      "[CV 2/3] END C=0.0505, dual=True, loss=hinge, max_iter=5000, penalty=l2; accuracy: (test=0.900) f1_micro: (test=0.900) recall_macro: (test=0.900) total time=   5.4s\n",
      "[CV 3/3] END C=0.0505, dual=True, loss=hinge, max_iter=5000, penalty=l2; accuracy: (test=0.901) f1_micro: (test=0.901) recall_macro: (test=0.901) total time=   5.7s\n",
      "[CV 1/3] END C=0.0505, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.5s\n",
      "[CV 2/3] END C=0.0505, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.5s\n",
      "[CV 3/3] END C=0.0505, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.7s\n",
      "[CV 1/3] END C=0.0505, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; accuracy: (test=0.896) f1_micro: (test=0.896) recall_macro: (test=0.896) total time=   6.4s\n",
      "[CV 2/3] END C=0.0505, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; accuracy: (test=0.898) f1_micro: (test=0.898) recall_macro: (test=0.898) total time=   5.1s\n",
      "[CV 3/3] END C=0.0505, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; accuracy: (test=0.899) f1_micro: (test=0.899) recall_macro: (test=0.899) total time=   5.3s\n",
      "[CV 1/3] END C=0.0505, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.3s\n",
      "[CV 2/3] END C=0.0505, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.5s\n",
      "[CV 3/3] END C=0.0505, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.6s\n",
      "[CV 1/3] END C=0.0505, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; accuracy: (test=0.896) f1_micro: (test=0.896) recall_macro: (test=0.896) total time=   6.1s\n",
      "[CV 2/3] END C=0.0505, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; accuracy: (test=0.898) f1_micro: (test=0.898) recall_macro: (test=0.898) total time=   5.8s\n",
      "[CV 3/3] END C=0.0505, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; accuracy: (test=0.899) f1_micro: (test=0.899) recall_macro: (test=0.899) total time=   5.3s\n",
      "[CV 1/3] END C=0.0505, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.5s\n",
      "[CV 2/3] END C=0.0505, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.5s\n",
      "[CV 3/3] END C=0.0505, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.5s\n",
      "[CV 1/3] END C=0.0505, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; accuracy: (test=0.896) f1_micro: (test=0.896) recall_macro: (test=0.896) total time=   5.3s\n",
      "[CV 2/3] END C=0.0505, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; accuracy: (test=0.898) f1_micro: (test=0.898) recall_macro: (test=0.898) total time=   5.8s\n",
      "[CV 3/3] END C=0.0505, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; accuracy: (test=0.899) f1_micro: (test=0.899) recall_macro: (test=0.899) total time=   5.4s\n",
      "[CV 1/3] END C=0.07525000000000001, dual=True, loss=hinge, max_iter=1000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.4s\n",
      "[CV 2/3] END C=0.07525000000000001, dual=True, loss=hinge, max_iter=1000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.3s\n",
      "[CV 3/3] END C=0.07525000000000001, dual=True, loss=hinge, max_iter=1000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.2s\n",
      "[CV 1/3] END C=0.07525000000000001, dual=True, loss=hinge, max_iter=1000, penalty=l2; accuracy: (test=0.899) f1_micro: (test=0.899) recall_macro: (test=0.899) total time=   5.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=0.07525000000000001, dual=True, loss=hinge, max_iter=1000, penalty=l2; accuracy: (test=0.900) f1_micro: (test=0.900) recall_macro: (test=0.900) total time=   5.2s\n",
      "[CV 3/3] END C=0.07525000000000001, dual=True, loss=hinge, max_iter=1000, penalty=l2; accuracy: (test=0.901) f1_micro: (test=0.901) recall_macro: (test=0.901) total time=   5.6s\n",
      "[CV 1/3] END C=0.07525000000000001, dual=True, loss=hinge, max_iter=3000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.4s\n",
      "[CV 2/3] END C=0.07525000000000001, dual=True, loss=hinge, max_iter=3000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.5s\n",
      "[CV 3/3] END C=0.07525000000000001, dual=True, loss=hinge, max_iter=3000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.2s\n",
      "[CV 1/3] END C=0.07525000000000001, dual=True, loss=hinge, max_iter=3000, penalty=l2; accuracy: (test=0.899) f1_micro: (test=0.899) recall_macro: (test=0.899) total time=   5.0s\n",
      "[CV 2/3] END C=0.07525000000000001, dual=True, loss=hinge, max_iter=3000, penalty=l2; accuracy: (test=0.900) f1_micro: (test=0.900) recall_macro: (test=0.900) total time=   6.0s\n",
      "[CV 3/3] END C=0.07525000000000001, dual=True, loss=hinge, max_iter=3000, penalty=l2; accuracy: (test=0.901) f1_micro: (test=0.901) recall_macro: (test=0.901) total time=   5.4s\n",
      "[CV 1/3] END C=0.07525000000000001, dual=True, loss=hinge, max_iter=5000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.4s\n",
      "[CV 2/3] END C=0.07525000000000001, dual=True, loss=hinge, max_iter=5000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.5s\n",
      "[CV 3/3] END C=0.07525000000000001, dual=True, loss=hinge, max_iter=5000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.5s\n",
      "[CV 1/3] END C=0.07525000000000001, dual=True, loss=hinge, max_iter=5000, penalty=l2; accuracy: (test=0.899) f1_micro: (test=0.899) recall_macro: (test=0.899) total time=   6.0s\n",
      "[CV 2/3] END C=0.07525000000000001, dual=True, loss=hinge, max_iter=5000, penalty=l2; accuracy: (test=0.900) f1_micro: (test=0.900) recall_macro: (test=0.900) total time=   5.9s\n",
      "[CV 3/3] END C=0.07525000000000001, dual=True, loss=hinge, max_iter=5000, penalty=l2; accuracy: (test=0.901) f1_micro: (test=0.901) recall_macro: (test=0.901) total time=   5.9s\n",
      "[CV 1/3] END C=0.07525000000000001, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.4s\n",
      "[CV 2/3] END C=0.07525000000000001, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.3s\n",
      "[CV 3/3] END C=0.07525000000000001, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.3s\n",
      "[CV 1/3] END C=0.07525000000000001, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; accuracy: (test=0.894) f1_micro: (test=0.894) recall_macro: (test=0.894) total time=   4.9s\n",
      "[CV 2/3] END C=0.07525000000000001, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; accuracy: (test=0.897) f1_micro: (test=0.897) recall_macro: (test=0.897) total time=   5.3s\n",
      "[CV 3/3] END C=0.07525000000000001, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; accuracy: (test=0.897) f1_micro: (test=0.897) recall_macro: (test=0.897) total time=   5.4s\n",
      "[CV 1/3] END C=0.07525000000000001, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.4s\n",
      "[CV 2/3] END C=0.07525000000000001, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.5s\n",
      "[CV 3/3] END C=0.07525000000000001, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.9s\n",
      "[CV 1/3] END C=0.07525000000000001, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; accuracy: (test=0.894) f1_micro: (test=0.894) recall_macro: (test=0.894) total time=   5.6s\n",
      "[CV 2/3] END C=0.07525000000000001, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; accuracy: (test=0.897) f1_micro: (test=0.897) recall_macro: (test=0.897) total time=   5.2s\n",
      "[CV 3/3] END C=0.07525000000000001, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; accuracy: (test=0.897) f1_micro: (test=0.897) recall_macro: (test=0.897) total time=   5.7s\n",
      "[CV 1/3] END C=0.07525000000000001, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.4s\n",
      "[CV 2/3] END C=0.07525000000000001, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.5s\n",
      "[CV 3/3] END C=0.07525000000000001, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.6s\n",
      "[CV 1/3] END C=0.07525000000000001, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; accuracy: (test=0.894) f1_micro: (test=0.894) recall_macro: (test=0.894) total time=   6.3s\n",
      "[CV 2/3] END C=0.07525000000000001, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; accuracy: (test=0.897) f1_micro: (test=0.897) recall_macro: (test=0.897) total time=   6.0s\n",
      "[CV 3/3] END C=0.07525000000000001, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; accuracy: (test=0.897) f1_micro: (test=0.897) recall_macro: (test=0.897) total time=   5.3s\n",
      "[CV 1/3] END C=0.1, dual=True, loss=hinge, max_iter=1000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.3s\n",
      "[CV 2/3] END C=0.1, dual=True, loss=hinge, max_iter=1000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.3s\n",
      "[CV 3/3] END C=0.1, dual=True, loss=hinge, max_iter=1000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.1, dual=True, loss=hinge, max_iter=1000, penalty=l2; accuracy: (test=0.898) f1_micro: (test=0.898) recall_macro: (test=0.898) total time=   5.4s\n",
      "[CV 2/3] END C=0.1, dual=True, loss=hinge, max_iter=1000, penalty=l2; accuracy: (test=0.900) f1_micro: (test=0.900) recall_macro: (test=0.900) total time=   5.4s\n",
      "[CV 3/3] END C=0.1, dual=True, loss=hinge, max_iter=1000, penalty=l2; accuracy: (test=0.901) f1_micro: (test=0.901) recall_macro: (test=0.901) total time=   5.4s\n",
      "[CV 1/3] END C=0.1, dual=True, loss=hinge, max_iter=3000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.5s\n",
      "[CV 2/3] END C=0.1, dual=True, loss=hinge, max_iter=3000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   3.2s\n",
      "[CV 3/3] END C=0.1, dual=True, loss=hinge, max_iter=3000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.5s\n",
      "[CV 1/3] END C=0.1, dual=True, loss=hinge, max_iter=3000, penalty=l2; accuracy: (test=0.898) f1_micro: (test=0.898) recall_macro: (test=0.898) total time=   5.6s\n",
      "[CV 2/3] END C=0.1, dual=True, loss=hinge, max_iter=3000, penalty=l2; accuracy: (test=0.900) f1_micro: (test=0.900) recall_macro: (test=0.900) total time=   5.0s\n",
      "[CV 3/3] END C=0.1, dual=True, loss=hinge, max_iter=3000, penalty=l2; accuracy: (test=0.901) f1_micro: (test=0.901) recall_macro: (test=0.901) total time=   5.6s\n",
      "[CV 1/3] END C=0.1, dual=True, loss=hinge, max_iter=5000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.4s\n",
      "[CV 2/3] END C=0.1, dual=True, loss=hinge, max_iter=5000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.5s\n",
      "[CV 3/3] END C=0.1, dual=True, loss=hinge, max_iter=5000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.6s\n",
      "[CV 1/3] END C=0.1, dual=True, loss=hinge, max_iter=5000, penalty=l2; accuracy: (test=0.898) f1_micro: (test=0.898) recall_macro: (test=0.898) total time=   6.6s\n",
      "[CV 2/3] END C=0.1, dual=True, loss=hinge, max_iter=5000, penalty=l2; accuracy: (test=0.900) f1_micro: (test=0.900) recall_macro: (test=0.900) total time=   6.0s\n",
      "[CV 3/3] END C=0.1, dual=True, loss=hinge, max_iter=5000, penalty=l2; accuracy: (test=0.901) f1_micro: (test=0.901) recall_macro: (test=0.901) total time=   5.4s\n",
      "[CV 1/3] END C=0.1, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.4s\n",
      "[CV 2/3] END C=0.1, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.3s\n",
      "[CV 3/3] END C=0.1, dual=True, loss=squared_hinge, max_iter=1000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.1s\n",
      "[CV 1/3] END C=0.1, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; accuracy: (test=0.893) f1_micro: (test=0.893) recall_macro: (test=0.893) total time=   5.0s\n",
      "[CV 2/3] END C=0.1, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; accuracy: (test=0.894) f1_micro: (test=0.894) recall_macro: (test=0.894) total time=   5.6s\n",
      "[CV 3/3] END C=0.1, dual=True, loss=squared_hinge, max_iter=1000, penalty=l2; accuracy: (test=0.894) f1_micro: (test=0.894) recall_macro: (test=0.894) total time=   5.6s\n",
      "[CV 1/3] END C=0.1, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.5s\n",
      "[CV 2/3] END C=0.1, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.5s\n",
      "[CV 3/3] END C=0.1, dual=True, loss=squared_hinge, max_iter=3000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.5s\n",
      "[CV 1/3] END C=0.1, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; accuracy: (test=0.893) f1_micro: (test=0.893) recall_macro: (test=0.893) total time=   5.6s\n",
      "[CV 2/3] END C=0.1, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; accuracy: (test=0.894) f1_micro: (test=0.894) recall_macro: (test=0.894) total time=   5.6s\n",
      "[CV 3/3] END C=0.1, dual=True, loss=squared_hinge, max_iter=3000, penalty=l2; accuracy: (test=0.894) f1_micro: (test=0.894) recall_macro: (test=0.894) total time=   6.2s\n",
      "[CV 1/3] END C=0.1, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.6s\n",
      "[CV 2/3] END C=0.1, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.5s\n",
      "[CV 3/3] END C=0.1, dual=True, loss=squared_hinge, max_iter=5000, penalty=l1; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.5s\n",
      "[CV 1/3] END C=0.1, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; accuracy: (test=0.893) f1_micro: (test=0.893) recall_macro: (test=0.893) total time=   6.0s\n",
      "[CV 2/3] END C=0.1, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; accuracy: (test=0.894) f1_micro: (test=0.894) recall_macro: (test=0.894) total time=   5.8s\n",
      "[CV 3/3] END C=0.1, dual=True, loss=squared_hinge, max_iter=5000, penalty=l2; accuracy: (test=0.894) f1_micro: (test=0.894) recall_macro: (test=0.894) total time=   5.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "90 fits failed out of a total of 180.\n",
      "The score on these train-test partitions for these parameters will be set to 0.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/habkaffee/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/habkaffee/.local/lib/python3.10/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/home/habkaffee/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 326, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/habkaffee/.local/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1229, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/habkaffee/.local/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1060, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/habkaffee/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/habkaffee/.local/lib/python3.10/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/home/habkaffee/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py\", line 326, in fit\n",
      "    self.coef_, self.intercept_, n_iter_ = _fit_liblinear(\n",
      "  File \"/home/habkaffee/.local/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1229, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/home/habkaffee/.local/lib/python3.10/site-packages/sklearn/svm/_base.py\", line 1060, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator -> LinearSVC(C=0.0505, dual=True, loss='hinge', max_iter=3000)\n",
      "Best Score -> 0.9003333333333333\n",
      "Best Parameters -> {'C': 0.0505, 'dual': True, 'loss': 'hinge', 'max_iter': 3000, 'penalty': 'l2'}\n",
      "Best index -> 27\n"
     ]
    }
   ],
   "source": [
    "parameters_linSVC = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'loss': ['hinge', 'squared_hinge'],\n",
    "    'C': np.linspace(0.001, 0.1, 5),\n",
    "    'max_iter': [1000, 3000, 5000],\n",
    "    'dual':[True]\n",
    "}\n",
    "\n",
    "grid_linearSVC = get_gridsearch_for_model(LinearSVC(), parameters_linSVC)\n",
    "\n",
    "grid_linearSVC.fit(X_train, Y_train)\n",
    "print_grid_search_info(grid_linearSVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y_pred_linSVC = grid_linearSVC.predict(X_test)\n",
    "print_metrics(Y_test, Y_pred_linSVC)\n",
    "save_model('./models/lin_svc_trash.pkl', grid_linearSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CVect_digits = vectorizer.fit_transform(train_removed_digits).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CVect_punctuation = vectorizer.fit_transform(train_removed_punctuation).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_metrix_df(metrix, name, accuracy, recall, precision):\n",
    "    metrix[name] = [accuracy, recall, precision]\n",
    "\n",
    "all_metrics_df = pd.DataFrame(index=['Accuracy', 'Recall', 'Precision'])\n",
    "fill_metrix_df(all_metrics_df, 'LogisticRegression',\n",
    "                accuracy_score(Y_test, Y_pred_logreg), \n",
    "                recall_score(Y_test, Y_pred_logreg, average='macro'), \n",
    "                precision_score(Y_test, Y_pred_logreg, average='macro'))\n",
    "fill_metrix_df(all_metrics_df, 'LinearSVC',\n",
    "                accuracy_score(Y_test, Y_pred_linearSVC), \n",
    "                recall_score(Y_test, Y_pred_linearSVC, average='macro'), \n",
    "                precision_score(Y_test, Y_pred_linearSVC, average='macro'))\n",
    "fill_metrix_df(all_metrics_df, 'KNeigborsClassifier',\n",
    "                accuracy_score(Y_test, Y_pred_KNN), \n",
    "                recall_score(Y_test, Y_pred_KNN, average='macro'), \n",
    "                precision_score(Y_test, Y_pred_KNN, average='macro'))\n",
    "fill_metrix_df(all_metrics_df, 'RandomForestClassifier',\n",
    "                accuracy_score(Y_test, Y_pred_RFC), \n",
    "                recall_score(Y_test, Y_pred_RFC, average='macro'), \n",
    "                precision_score(Y_test, Y_pred_RFC, average='macro'))\n",
    "fill_metrix_df(all_metrics_df, 'GradientBoostingClassifier',\n",
    "                accuracy_score(Y_test, Y_pred_GBC), \n",
    "                recall_score(Y_test, Y_pred_GBC, average='macro'), \n",
    "                precision_score(Y_test, Y_pred_GBC, average='macro'))\n",
    "fill_metrix_df(all_metrics_df, 'MultinomialNB',\n",
    "                accuracy_score(Y_test, Y_pred_MNB), \n",
    "                recall_score(Y_test, Y_pred_MNB, average='macro'), \n",
    "                precision_score(Y_test, Y_pred_MNB, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_conf_matrix(y_true, y_pred):\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    cm_display = ConfusionMatrixDisplay(conf_matrix, display_labels=df.category.unique())\n",
    "    cm_display.plot()\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_conf_matrix(Y_test, Y_pred_logreg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, Logistic regression have a few problems with prediction of two categories: \"nauka\" and \"hitech\"."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_conf_matrix(Y_test, Y_pred_linearSVC)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LinearSVC model have confused \"nauka\" and \"hitech\" more often like LogisticRegression."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNeigboursClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_conf_matrix(Y_test, Y_pred_KNN)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNeigbors classifier confused almost everything, and now it's clear why it has the lowest scores between others."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_conf_matrix(Y_test, Y_pred_GBC)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GradientBoosting classifier has more confusions between \"nauka\" and \"hitech\" than logistic regression and LinearSVC."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_conf_matrix(Y_test, Y_pred_RFC)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, RandomForest classifier good at prediction of \"auto\" label, but that classifier, like others, confuse \"hitech\" and \"nauka\"."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_conf_matrix(Y_test, Y_pred_MNB)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like other models, MultinonialNB confuses \"nauka\" and \"hitech\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All metrics are displayed below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e6463d715e1378e337fc3da88af56f170e8b2fc8216e6f94629c44ee68539bbe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
