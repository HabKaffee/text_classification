{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pymorphy2\n",
    "# %pip install nltk\n",
    "# %pip install sklearn\n",
    "# %pip install wordcloud\n",
    "# %pip install stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "import pymorphy2\n",
    "from scipy.sparse import *\n",
    "import stop_words\n",
    "import tqdm\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.metrics import precision_score, accuracy_score, recall_score, f1_score\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_conf_matrix(y_true, y_pred):\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    cm_display = ConfusionMatrixDisplay(conf_matrix, display_labels=Y.unique())\n",
    "    cm_display.plot()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_grid_search_info(model):\n",
    "    print(f'Best estimator -> {model.best_estimator_}\\n\\\n",
    "Best Score -> {model.best_score_}\\n\\\n",
    "Best Parameters -> {model.best_params_}\\n\\\n",
    "Best index -> {model.best_index_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gridsearch_for_model(model, parameters : dict) -> GridSearchCV:\n",
    "    model_grid = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=parameters,\n",
    "        scoring=['f1_micro', 'accuracy', 'recall_macro'],\n",
    "        refit='f1_micro',\n",
    "        cv=3,\n",
    "        verbose=3,\n",
    "        error_score=0\n",
    "    )\n",
    "    return model_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(path:str, model):\n",
    "    with open(path, mode='wb') as pickle_file:\n",
    "        pickle.dump(model, pickle_file)\n",
    "\n",
    "def load_model(path:str):\n",
    "    with open('./models/lin_svc.pkl', mode='rb') as pickle_file:\n",
    "        model = pickle.load(pickle_file)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(y_test, y_pred):\n",
    "    print(f'f1_micro = {f1_score(y_test, y_pred, average=\"micro\")}\\nrecall_score = {recall_score(y_test, y_pred, average=\"macro\")}\\nprecision_score = {precision_score(y_test, y_pred, average=\"macro\")}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class Index</th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Wall St. Bears Claw Back Into the Black (Reuters)</td>\n",
       "      <td>Reuters - Short-sellers, Wall Street's dwindli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
       "      <td>Reuters - Private investment firm Carlyle Grou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters)</td>\n",
       "      <td>Reuters - Soaring crude prices plus worries\\ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
       "      <td>Reuters - Authorities have halted oil export\\f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Oil prices soar to all-time record, posing new...</td>\n",
       "      <td>AFP - Tearaway world oil prices, toppling reco...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class Index                                              Title  \\\n",
       "0            3  Wall St. Bears Claw Back Into the Black (Reuters)   \n",
       "1            3  Carlyle Looks Toward Commercial Aerospace (Reu...   \n",
       "2            3    Oil and Economy Cloud Stocks' Outlook (Reuters)   \n",
       "3            3  Iraq Halts Oil Exports from Main Southern Pipe...   \n",
       "4            3  Oil prices soar to all-time record, posing new...   \n",
       "\n",
       "                                         Description  \n",
       "0  Reuters - Short-sellers, Wall Street's dwindli...  \n",
       "1  Reuters - Private investment firm Carlyle Grou...  \n",
       "2  Reuters - Soaring crude prices plus worries\\ab...  \n",
       "3  Reuters - Authorities have halted oil export\\f...  \n",
       "4  AFP - Tearaway world oil prices, toppling reco...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = pd.read_csv(\"data/test.csv\")\n",
    "train_dataset = pd.read_csv(\"data/train.csv\")\n",
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's prepare copies of train dataset with 4 different text cleaning techniques (one method at a time):  \n",
    "- stop words removing\n",
    "- punctuation removing\n",
    "- trash removing\n",
    "- digits removing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reuters - Short-sellers, Wall Street's dwindli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reuters - Private investment firm Carlyle Grou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Reuters - Soaring crude prices plus worries\\ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Reuters - Authorities have halted oil export\\f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFP - Tearaway world oil prices, toppling reco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119995</th>\n",
       "      <td>KARACHI (Reuters) - Pakistani President Perve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119996</th>\n",
       "      <td>Red Sox general manager Theo Epstein acknowled...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119997</th>\n",
       "      <td>The Miami Dolphins will put their courtship of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119998</th>\n",
       "      <td>PITTSBURGH at NY GIANTS Time: 1:30 p.m. Line: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119999</th>\n",
       "      <td>INDIANAPOLIS -- All-Star Vince Carter was trad...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        0\n",
       "0       Reuters - Short-sellers, Wall Street's dwindli...\n",
       "1       Reuters - Private investment firm Carlyle Grou...\n",
       "2       Reuters - Soaring crude prices plus worries\\ab...\n",
       "3       Reuters - Authorities have halted oil export\\f...\n",
       "4       AFP - Tearaway world oil prices, toppling reco...\n",
       "...                                                   ...\n",
       "119995   KARACHI (Reuters) - Pakistani President Perve...\n",
       "119996  Red Sox general manager Theo Epstein acknowled...\n",
       "119997  The Miami Dolphins will put their courtship of...\n",
       "119998  PITTSBURGH at NY GIANTS Time: 1:30 p.m. Line: ...\n",
       "119999  INDIANAPOLIS -- All-Star Vince Carter was trad...\n",
       "\n",
       "[120000 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_splitted_texts = [line.split('\\n') for line in train_dataset['Description']]\n",
    "pd.DataFrame(train_dataset_splitted_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reuters - Short-sellers, Wall Street's dwindli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reuters - Private investment firm Carlyle Grou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Reuters - Soaring crude prices plus worries\\ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Reuters - Authorities have halted oil export\\f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFP - Tearaway world oil prices, toppling reco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119995</th>\n",
       "      <td>KARACHI (Reuters) - Pakistani President Perve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119996</th>\n",
       "      <td>Red Sox general manager Theo Epstein acknowled...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119997</th>\n",
       "      <td>The Miami Dolphins will put their courtship of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119998</th>\n",
       "      <td>PITTSBURGH at NY GIANTS Time: 1:30 p.m. Line: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119999</th>\n",
       "      <td>INDIANAPOLIS -- All-Star Vince Carter was trad...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        0\n",
       "0       Reuters - Short-sellers, Wall Street's dwindli...\n",
       "1       Reuters - Private investment firm Carlyle Grou...\n",
       "2       Reuters - Soaring crude prices plus worries\\ab...\n",
       "3       Reuters - Authorities have halted oil export\\f...\n",
       "4       AFP - Tearaway world oil prices, toppling reco...\n",
       "...                                                   ...\n",
       "119995   KARACHI (Reuters) - Pakistani President Perve...\n",
       "119996  Red Sox general manager Theo Epstein acknowled...\n",
       "119997  The Miami Dolphins will put their courtship of...\n",
       "119998  PITTSBURGH at NY GIANTS Time: 1:30 p.m. Line: ...\n",
       "119999  INDIANAPOLIS -- All-Star Vince Carter was trad...\n",
       "\n",
       "[120000 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_removed_stopwords = [' '.join([word if word not in stop_words.get_stop_words('en') else '' for word in text]) for text in train_dataset_splitted_texts]\n",
    "pd.DataFrame(train_removed_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reuters  Shortsellers Wall Streets dwindlingba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reuters  Private investment firm Carlyle Group...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Reuters  Soaring crude prices plus worriesabou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Reuters  Authorities have halted oil exportflo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFP  Tearaway world oil prices toppling record...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119995</th>\n",
       "      <td>KARACHI Reuters  Pakistani President Pervez M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119996</th>\n",
       "      <td>Red Sox general manager Theo Epstein acknowled...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119997</th>\n",
       "      <td>The Miami Dolphins will put their courtship of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119998</th>\n",
       "      <td>PITTSBURGH at NY GIANTS Time 130 pm Line Steel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119999</th>\n",
       "      <td>INDIANAPOLIS  AllStar Vince Carter was traded ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        0\n",
       "0       Reuters  Shortsellers Wall Streets dwindlingba...\n",
       "1       Reuters  Private investment firm Carlyle Group...\n",
       "2       Reuters  Soaring crude prices plus worriesabou...\n",
       "3       Reuters  Authorities have halted oil exportflo...\n",
       "4       AFP  Tearaway world oil prices toppling record...\n",
       "...                                                   ...\n",
       "119995   KARACHI Reuters  Pakistani President Pervez M...\n",
       "119996  Red Sox general manager Theo Epstein acknowled...\n",
       "119997  The Miami Dolphins will put their courtship of...\n",
       "119998  PITTSBURGH at NY GIANTS Time 130 pm Line Steel...\n",
       "119999  INDIANAPOLIS  AllStar Vince Carter was traded ...\n",
       "\n",
       "[120000 rows x 1 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_removed_punctuation = [' '.join([(' '.join(text)).translate(str.maketrans('', '', str(\"!\\\"\\'(),-./:;?\\\\`\")))]) for text in train_dataset_splitted_texts]\n",
    "pd.DataFrame(train_removed_punctuation)\n",
    "# train_removed_punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_symbols = u''.join(['№', '«', 'ђ', '°', '±', '‚', 'ћ', '‰', '…', '»', 'ѓ', 'µ', '·', 'ґ', 'њ', 'ї', 'џ', 'є', '‹',\n",
    "                            '‡', '†', '¶', 'ќ', '€', '“', 'ў', '§', '„', '”', '\\ufeff', '’', 'љ', '›', '•', '—', '‘', \n",
    "                            '\\x7f', '\\xad', '¤', '\\xa0', '\\u200b', '–']) + string.punctuation\n",
    "regex_symb = re.compile('[%s]' % re.escape(exclude_symbols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reuters Shortsellers Wall Streets dwindlingban...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reuters Private investment firm Carlyle Groupw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Reuters Soaring crude prices plus worriesabout...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Reuters Authorities have halted oil exportflow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFP Tearaway world oil prices toppling records...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119995</th>\n",
       "      <td>KARACHI Reuters Pakistani President Pervez Mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119996</th>\n",
       "      <td>Red Sox general manager Theo Epstein acknowled...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119997</th>\n",
       "      <td>The Miami Dolphins will put their courtship of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119998</th>\n",
       "      <td>PITTSBURGH at NY GIANTS Time 130 pm Line Steel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119999</th>\n",
       "      <td>INDIANAPOLIS AllStar Vince Carter was traded b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        0\n",
       "0       Reuters Shortsellers Wall Streets dwindlingban...\n",
       "1       Reuters Private investment firm Carlyle Groupw...\n",
       "2       Reuters Soaring crude prices plus worriesabout...\n",
       "3       Reuters Authorities have halted oil exportflow...\n",
       "4       AFP Tearaway world oil prices toppling records...\n",
       "...                                                   ...\n",
       "119995   KARACHI Reuters Pakistani President Pervez Mu...\n",
       "119996  Red Sox general manager Theo Epstein acknowled...\n",
       "119997  The Miami Dolphins will put their courtship of...\n",
       "119998  PITTSBURGH at NY GIANTS Time 130 pm Line Steel...\n",
       "119999  INDIANAPOLIS AllStar Vince Carter was traded b...\n",
       "\n",
       "[120000 rows x 1 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_removed_trash = [regex_symb.sub('', ' '.join(text)) for text in train_dataset_splitted_texts]\n",
    "train_removed_trash = [re.sub(r' +', ' ', text) for text in train_removed_trash]\n",
    "pd.DataFrame(train_removed_trash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reuters - Short-sellers, Wall Street's dwindli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reuters - Private investment firm Carlyle Grou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Reuters - Soaring crude prices plus worries\\ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Reuters - Authorities have halted oil export\\f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFP - Tearaway world oil prices, toppling reco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119995</th>\n",
       "      <td>KARACHI (Reuters) - Pakistani President Perve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119996</th>\n",
       "      <td>Red Sox general manager Theo Epstein acknowled...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119997</th>\n",
       "      <td>The Miami Dolphins will put their courtship of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119998</th>\n",
       "      <td>PITTSBURGH at NY GIANTS Time: : p.m. Line: Ste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119999</th>\n",
       "      <td>INDIANAPOLIS -- All-Star Vince Carter was trad...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        0\n",
       "0       Reuters - Short-sellers, Wall Street's dwindli...\n",
       "1       Reuters - Private investment firm Carlyle Grou...\n",
       "2       Reuters - Soaring crude prices plus worries\\ab...\n",
       "3       Reuters - Authorities have halted oil export\\f...\n",
       "4       AFP - Tearaway world oil prices, toppling reco...\n",
       "...                                                   ...\n",
       "119995   KARACHI (Reuters) - Pakistani President Perve...\n",
       "119996  Red Sox general manager Theo Epstein acknowled...\n",
       "119997  The Miami Dolphins will put their courtship of...\n",
       "119998  PITTSBURGH at NY GIANTS Time: : p.m. Line: Ste...\n",
       "119999  INDIANAPOLIS -- All-Star Vince Carter was trad...\n",
       "\n",
       "[120000 rows x 1 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex_digit = re.compile('[%s]' % re.escape(string.digits))\n",
    "train_removed_digits = [regex_digit.sub('', ' '.join(text)) for text in train_dataset_splitted_texts]\n",
    "pd.DataFrame(train_removed_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words=stop_words.get_stop_words('en'), max_features=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = train_dataset[\"Class Index\"]\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/.local/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aren', 'can', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'let', 'll', 'mustn', 're', 'shan', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "CVect_stopwords = vectorizer.fit_transform(train_removed_stopwords).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(CVect_stopwords, Y, test_size=0.25, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_logreg = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.01, 0.1, 0.5, 1.0, 10.0],\n",
    "    'solver': ['lbfgs', 'liblinear'],\n",
    "    'max_iter': [100, 500]\n",
    "}\n",
    "\n",
    "grid_log = get_gridsearch_for_model(LogisticRegression(), parameters_logreg)\n",
    "\n",
    "grid_log.fit(X_train, Y_train)\n",
    "print_grid_search_info(grid_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score = 0.9016666666666667\n",
      "recall_score = 0.9014730717851448\n",
      "precision_score = 0.9013132593705164\n"
     ]
    }
   ],
   "source": [
    "Y_pred_logreg = grid_log.predict(X_test)\n",
    "print_metrics(Y_test, Y_pred_logreg)\n",
    "save_model('./models/log_reg.pkl', grid_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_linSVC = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'loss': ['hinge', 'squared_hinge'],\n",
    "    'C': np.linspace(0.001, 0.1, 5),\n",
    "    'max_iter': [1000, 3000, 5000],\n",
    "    'dual':[True]\n",
    "}\n",
    "\n",
    "grid_linearSVC = get_gridsearch_for_model(LinearSVC(), parameters_linSVC)\n",
    "\n",
    "grid_linearSVC.fit(X_train, Y_train)\n",
    "print_grid_search_info(grid_linearSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score = 0.9051999999999999\n",
      "recall_score = 0.9050006500418074\n",
      "precision_score = 0.9049231276210165\n"
     ]
    }
   ],
   "source": [
    "Y_pred_linSVC = grid_linearSVC.predict(X_test)\n",
    "print_metrics(Y_test, Y_pred_linSVC)\n",
    "save_model('./models/lin_svc.pkl', grid_linearSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters_RFC = {\n",
    "#     'n_estimators': [10, 50, 100, 300],\n",
    "#     'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "#     'max_features': ['sqrt', 'log2'],\n",
    "# }\n",
    "\n",
    "# grid_RFC = get_gridsearch_for_model(RandomForestClassifier(), parameters_RFC)\n",
    "\n",
    "# grid_RFC.fit(X_train, Y_train)\n",
    "# print_grid_search_info(grid_RFC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_pred_RFC = grid_RFC.predict(X_test)\n",
    "# print_metrics(Y_test, Y_pred_RFC)\n",
    "# save_model('./models/RFC.pkl', grid_RFC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_KNN = {\n",
    "    'n_neighbors' : [5, 6, 7],\n",
    "    'weights' : ['uniform', 'distance'],\n",
    "    'leaf_size' : [1, 2, 3],\n",
    "    'n_jobs' : [10]\n",
    "}\n",
    "\n",
    "grid_KNN = get_gridsearch_for_model(KNeighborsClassifier(), parameters_KNN)\n",
    "\n",
    "grid_KNN.fit(X_train, Y_train)\n",
    "print_grid_search_info(grid_KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score = 0.5876333333333333\n",
      "recall_score = 0.5868685205825099\n",
      "precision_score = 0.6719880795980494\n"
     ]
    }
   ],
   "source": [
    "Y_pred_KNN = grid_KNN.predict(X_test)\n",
    "print_metrics(Y_test, Y_pred_KNN)\n",
    "save_model('./models/KNN.pkl', grid_RFC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters_MNB = {\n",
    "#     'alpha' : np.linspace(0.3, 0.4, 100)\n",
    "# }\n",
    "\n",
    "# grid_MNB = get_gridsearch_for_model(MultinomialNB(),parameters_MNB)\n",
    "\n",
    "# grid_MNB.fit(X_train, Y_train)\n",
    "# print_grid_search_info(grid_MNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_pred_MNB = grid_MNB.predict(X_test)\n",
    "# print_metrics(Y_test, Y_pred_MNB)\n",
    "# save_model('./models/MNB.pkl', grid_RFC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/.local/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aren', 'can', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'let', 'll', 'mustn', 're', 'shan', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "CVect_trash = vectorizer.fit_transform(train_removed_trash).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(CVect_trash, Y, test_size=0.25, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_logreg = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.01, 0.1, 0.5, 1.0, 10.0],\n",
    "    'solver': ['lbfgs', 'liblinear'],\n",
    "    'max_iter': [100, 500]\n",
    "}\n",
    "\n",
    "grid_log = get_gridsearch_for_model(LogisticRegression(), parameters_logreg)\n",
    "\n",
    "grid_log.fit(X_train, Y_train)\n",
    "print_grid_search_info(grid_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score = 0.8989\n",
      "recall_score = 0.8987174214816545\n",
      "precision_score = 0.8985895429774059\n"
     ]
    }
   ],
   "source": [
    "Y_pred_logreg = grid_log.predict(X_test)\n",
    "print_metrics(Y_test, Y_pred_logreg)\n",
    "save_model('./models/log_reg_trash.pkl', grid_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_linSVC = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'loss': ['hinge', 'squared_hinge'],\n",
    "    'C': np.linspace(0.001, 0.1, 5),\n",
    "    'max_iter': [1000, 3000, 5000],\n",
    "    'dual':[True]\n",
    "}\n",
    "\n",
    "grid_linearSVC = get_gridsearch_for_model(LinearSVC(), parameters_linSVC)\n",
    "\n",
    "grid_linearSVC.fit(X_train, Y_train)\n",
    "print_grid_search_info(grid_linearSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_linSVC = grid_linearSVC.predict(X_test)\n",
    "print_metrics(Y_test, Y_pred_linSVC)\n",
    "save_model('./models/lin_svc_trash.pkl', grid_linearSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/habkaffee/.local/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aren', 'can', 'couldn', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'let', 'll', 'mustn', 're', 'shan', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "CVect_digits = vectorizer.fit_transform(train_removed_digits).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(CVect_digits, Y, test_size=0.25, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n",
      "[CV 1/3] END C=0.01, max_iter=100, penalty=l1, solver=lbfgs; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   2.4s\n",
      "[CV 2/3] END C=0.01, max_iter=100, penalty=l1, solver=lbfgs; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   1.6s\n",
      "[CV 3/3] END C=0.01, max_iter=100, penalty=l1, solver=lbfgs; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   1.7s\n",
      "[CV 1/3] END C=0.01, max_iter=100, penalty=l1, solver=liblinear; accuracy: (test=0.793) f1_micro: (test=0.793) recall_macro: (test=0.793) total time=   7.5s\n",
      "[CV 2/3] END C=0.01, max_iter=100, penalty=l1, solver=liblinear; accuracy: (test=0.793) f1_micro: (test=0.793) recall_macro: (test=0.793) total time=   6.8s\n",
      "[CV 3/3] END C=0.01, max_iter=100, penalty=l1, solver=liblinear; accuracy: (test=0.794) f1_micro: (test=0.794) recall_macro: (test=0.794) total time=   6.8s\n",
      "[CV 1/3] END C=0.01, max_iter=100, penalty=l2, solver=lbfgs; accuracy: (test=0.884) f1_micro: (test=0.884) recall_macro: (test=0.884) total time= 2.2min\n",
      "[CV 2/3] END C=0.01, max_iter=100, penalty=l2, solver=lbfgs; accuracy: (test=0.882) f1_micro: (test=0.882) recall_macro: (test=0.882) total time= 2.0min\n",
      "[CV 3/3] END C=0.01, max_iter=100, penalty=l2, solver=lbfgs; accuracy: (test=0.883) f1_micro: (test=0.883) recall_macro: (test=0.883) total time= 2.0min\n",
      "[CV 1/3] END C=0.01, max_iter=100, penalty=l2, solver=liblinear; accuracy: (test=0.879) f1_micro: (test=0.879) recall_macro: (test=0.879) total time=  11.3s\n",
      "[CV 2/3] END C=0.01, max_iter=100, penalty=l2, solver=liblinear; accuracy: (test=0.877) f1_micro: (test=0.877) recall_macro: (test=0.877) total time=  10.3s\n",
      "[CV 3/3] END C=0.01, max_iter=100, penalty=l2, solver=liblinear; accuracy: (test=0.879) f1_micro: (test=0.879) recall_macro: (test=0.879) total time=  10.6s\n",
      "[CV 1/3] END C=0.01, max_iter=500, penalty=l1, solver=lbfgs; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   1.5s\n",
      "[CV 2/3] END C=0.01, max_iter=500, penalty=l1, solver=lbfgs; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   1.4s\n",
      "[CV 3/3] END C=0.01, max_iter=500, penalty=l1, solver=lbfgs; accuracy: (test=0.000) f1_micro: (test=0.000) recall_macro: (test=0.000) total time=   1.6s\n",
      "[CV 1/3] END C=0.01, max_iter=500, penalty=l1, solver=liblinear; accuracy: (test=0.793) f1_micro: (test=0.793) recall_macro: (test=0.793) total time=   7.3s\n",
      "[CV 2/3] END C=0.01, max_iter=500, penalty=l1, solver=liblinear; accuracy: (test=0.793) f1_micro: (test=0.793) recall_macro: (test=0.793) total time=   7.3s\n",
      "[CV 3/3] END C=0.01, max_iter=500, penalty=l1, solver=liblinear; accuracy: (test=0.794) f1_micro: (test=0.794) recall_macro: (test=0.794) total time=   6.3s\n",
      "[CV 1/3] END C=0.01, max_iter=500, penalty=l2, solver=lbfgs; accuracy: (test=0.884) f1_micro: (test=0.884) recall_macro: (test=0.884) total time= 2.1min\n"
     ]
    }
   ],
   "source": [
    "parameters_logreg = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.01, 0.1, 0.5, 1.0, 10.0],\n",
    "    'solver': ['lbfgs', 'liblinear'],\n",
    "    'max_iter': [100, 500]\n",
    "}\n",
    "\n",
    "grid_log = get_gridsearch_for_model(LogisticRegression(), parameters_logreg)\n",
    "\n",
    "grid_log.fit(X_train, Y_train)\n",
    "print_grid_search_info(grid_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_logreg = grid_log.predict(X_test)\n",
    "print_metrics(Y_test, Y_pred_logreg)\n",
    "save_model('./models/log_reg_digits.pkl', grid_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_linSVC = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'loss': ['hinge', 'squared_hinge'],\n",
    "    'C': np.linspace(0.001, 0.1, 5),\n",
    "    'max_iter': [1000, 3000, 5000],\n",
    "    'dual':[True]\n",
    "}\n",
    "\n",
    "grid_linearSVC = get_gridsearch_for_model(LinearSVC(), parameters_linSVC)\n",
    "\n",
    "grid_linearSVC.fit(X_train, Y_train)\n",
    "print_grid_search_info(grid_linearSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_linSVC = grid_linearSVC.predict(X_test)\n",
    "print_metrics(Y_test, Y_pred_linSVC)\n",
    "save_model('./models/lin_svc_digits.pkl', grid_linearSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CVect_punctuation = vectorizer.fit_transform(train_removed_punctuation).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_metrix_df(metrix, name, accuracy, recall, precision):\n",
    "    metrix[name] = [accuracy, recall, precision]\n",
    "\n",
    "all_metrics_df = pd.DataFrame(index=['f1_micro', 'Recall', 'Precision'])\n",
    "fill_metrix_df(all_metrics_df, 'LogisticRegression',\n",
    "                f1_micro(Y_test, Y_pred_logreg), \n",
    "                recall_score(Y_test, Y_pred_logreg, average='macro'), \n",
    "                precision_score(Y_test, Y_pred_logreg, average='macro'))\n",
    "fill_metrix_df(all_metrics_df, 'LinearSVC',\n",
    "                accuracy_score(Y_test, Y_pred_linearSVC), \n",
    "                recall_score(Y_test, Y_pred_linearSVC, average='macro'), \n",
    "                precision_score(Y_test, Y_pred_linearSVC, average='macro'))\n",
    "# fill_metrix_df(all_metrics_df, 'MultinomialNB',\n",
    "#                 accuracy_score(Y_test, Y_pred_MNB), \n",
    "#                 recall_score(Y_test, Y_pred_MNB, average='macro'), \n",
    "#                 precision_score(Y_test, Y_pred_MNB, average='macro'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_conf_matrix(Y_test, Y_pred_logreg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, Logistic regression have a few problems with prediction of two categories: \"nauka\" and \"hitech\"."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_conf_matrix(Y_test, Y_pred_linearSVC)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LinearSVC model have confused \"nauka\" and \"hitech\" more often like LogisticRegression."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNeigboursClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_conf_matrix(Y_test, Y_pred_KNN)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNeigbors classifier confused almost everything, and now it's clear why it has the lowest scores between others."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_conf_matrix(Y_test, Y_pred_GBC)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GradientBoosting classifier has more confusions between \"nauka\" and \"hitech\" than logistic regression and LinearSVC."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_conf_matrix(Y_test, Y_pred_RFC)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, RandomForest classifier good at prediction of \"auto\" label, but that classifier, like others, confuse \"hitech\" and \"nauka\"."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_conf_matrix(Y_test, Y_pred_MNB)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like other models, MultinonialNB confuses \"nauka\" and \"hitech\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All metrics are displayed below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e6463d715e1378e337fc3da88af56f170e8b2fc8216e6f94629c44ee68539bbe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
